{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conditional Text Generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOpI5DOPjh/eF6glhD+mAxQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charithcherry/Text-completion-NLP/blob/master/Conditional%20Text%20Generation%20by%20Fine%20Tuning%20GPT-2/Conditional_Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4fMMIa3mQRc"
      },
      "source": [
        "**Finetuning GPT-2 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxLbs8zWlixu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffe10bca-31bc-4999-ecfd-39bfda4a37d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/gpt2finetune"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/gpt2finetune\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjgni8HVSI1H",
        "outputId": "24d743e0-0d23-445a-a11e-b26c6fab1fe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTORS.md  Dockerfile.gpu     encode.py\t   README.md\t     train.py\n",
            "DEVELOPERS.md\t domains.txt\t    LICENSE\t   requirements.txt  twremat\n",
            "Dockerfile.cpu\t download_model.py  model_card.md  src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR9wx9dzli1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33e8f8c-9718-4ac7-db60-a0bd9b23550a"
      },
      "source": [
        "!git clone https://github.com/nshepperd/gpt-2\n",
        "%cd gpt-2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 435, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 435 (delta 19), reused 48 (delta 13), pack-reused 371\u001b[K\n",
            "Receiving objects: 100% (435/435), 4.48 MiB | 12.26 MiB/s, done.\n",
            "Resolving deltas: 100% (220/220), done.\n",
            "/content/drive/My Drive/gpt2finetune/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qjb4_almoPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343ce549-5218-4203-e27a-0a54bf9a21c8"
      },
      "source": [
        "!python download_model.py 124M\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 1.05Mit/s]                                                     \n",
            "Fetching encoder.json: 1.04Mit [00:00, 3.36Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.06Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:17, 28.2Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 5.81Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 1.75Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 1.79Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSK40h_vl6cP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0328d6-9ad9-47b7-ae34-2703e1f95def"
      },
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5\n",
            "  Downloading regex-2017.04.05.tar.gz (601 kB)\n",
            "\u001b[K     |████████████████████████████████| 601 kB 12.2 MB/s \n",
            "\u001b[?25hCollecting requests==2.21.0\n",
            "  Downloading requests-2.21.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.31.1\n",
            "  Downloading tqdm-4.31.1-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting toposort==1.5\n",
            "  Downloading toposort-1.5-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Collecting idna<2.9,>=2.5\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Building wheels for collected packages: regex, fire\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp37-cp37m-linux_x86_64.whl size=534430 sha256=5349ebb3590f1e14309a4074d5074c6edc3d6c9d9721f4eaf891b634b5a8b326\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/e8/a5/d4894e7ef29935f75c6074409ce8ca80a0271f0ce2a30da5d3\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=1c64290dae99c239fce1e1739648de29c3096c99b71b20bb31f6099821421f4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built regex fire\n",
            "Installing collected packages: idna, tqdm, toposort, requests, regex, fire\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.21.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.31.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed fire-0.4.0 idna-2.8 regex-2017.4.5 requests-2.21.0 toposort-1.5 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNbl6WMSmfVy"
      },
      "source": [
        "!chmod 755 -R /content/drive/MyDrive/gpt2finetune/gpt-2\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUXEFrcRmfZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c20f71-71d3-4401-fd70-fe84f371ffd0"
      },
      "source": [
        "%cd /content/drive/MyDrive/Corpus\n",
        "!export PYTHONIOENCODING=UTF-8\n",
        "%cd /content/drive/MyDrive/gpt2finetune/gpt-2"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Corpus\n",
            "/content/drive/MyDrive/gpt2finetune/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg453hYMm0Iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32978570-046a-4864-d782-3140ce8db05e"
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.0 \n",
        "!pip install ‘tensorflow-estimator<1.15.0rc0,>=1.14.0rc0’ — force-reinstall"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15.0\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 7.8 kB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.17.3)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 34.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.34.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (57.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (4.6.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.5.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7553 sha256=0e58d2ff56e0276eb18ec488312f38be83b7fef512fd95f165aeffc5f010917e\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires gast==0.4.0, but you have gast 0.2.2 which is incompatible.\n",
            "tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 1.15.0 which is incompatible.\n",
            "tensorflow 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 1.15.1 which is incompatible.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n",
            "/bin/bash: 1.15.0rc0,: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbEym1caWSAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea4742b-c2c7-4054-b8df-29ee3de3a2c9"
      },
      "source": [
        "%cd /content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riGBej9oYFkF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu1yTW5FnKVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3327fcc7-dff4-442a-b179-6f7fae9bbd82"
      },
      "source": [
        "!PYTHONPATH=src ./train.py  --dataset /content/drive/MyDrive/Corpus/shakespeare.txt --model_name '124M'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-31 08:36:21.603593: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-31 08:36:21.638916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-31 08:36:21.639473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-07-31 08:36:21.639773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-07-31 08:36:21.640844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-07-31 08:36:21.641883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-07-31 08:36:21.642200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-07-31 08:36:21.643400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-07-31 08:36:21.644291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-07-31 08:36:21.647175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-31 08:36:21.647285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-31 08:36:21.647866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-31 08:36:21.648364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-07-31 08:36:21.648760: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-07-31 08:36:21.653636: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-07-31 08:36:21.653825: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562ac290e840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-31 08:36:21.653853: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-07-31 08:36:21.841882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-31 08:36:21.842877: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562ac290ef40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-31 08:36:21.842946: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-07-31 08:36:21.843564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-31 08:36:21.846268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-07-31 08:36:21.846357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-07-31 08:36:21.846379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-07-31 08:36:21.846397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-07-31 08:36:21.846423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-07-31 08:36:21.846440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-07-31 08:36:21.846457: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-07-31 08:36:21.846474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-31 08:36:21.846599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-31 08:36:21.849264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-31 08:36:21.850651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-07-31 08:36:21.850747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-07-31 08:36:21.852904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-31 08:36:21.852939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-07-31 08:36:21.852954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-07-31 08:36:21.853083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-31 08:36:21.853942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-31 08:36:21.854694: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-31 08:36:21.854748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Traceback (most recent call last):\n",
            "  File \"./train.py\", line 314, in <module>\n",
            "    main()\n",
            "  File \"./train.py\", line 98, in main\n",
            "    with tf.Session() as sess:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1585, in __init__\n",
            "    super(Session, self).__init__(target, graph, config=config)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 699, in __init__\n",
            "    self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWyIgvYFoPHd"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/gpt2finetune/gpt-2/checkpoint/run1/* /content/drive/MyDrive/gpt2finetune/gpt-2/models/124M/"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il0FVF7kZC4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995fad6e-f843-471a-9139-4f184c5a9a81"
      },
      "source": [
        "%cd /content/drive/MyDrive/gpt2finetune/gpt-2]/src/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2/src/'\n",
            "/content/drive/MyDrive/gpt2finetune/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4tV89s6tzN0",
        "outputId": "6f3052f5-99ac-4ce4-c0b7-c4cd0e75323e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t Dockerfile.gpu     LICENSE\t   requirements.txt  twremat\n",
            "CONTRIBUTORS.md  domains.txt\t    model_card.md  samples\n",
            "DEVELOPERS.md\t download_model.py  models\t   src\n",
            "Dockerfile.cpu\t encode.py\t    README.md\t   train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wonSh4yhnOt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73b918c-f22c-4188-f393-a9d633148bdb"
      },
      "source": [
        "!python src/interactive_conditional_samples.py — top_k 40\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 91, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 47, in interact_model\n",
            "    enc = encoder.get_encoder(model_name, models_dir)\n",
            "  File \"/content/drive/My Drive/gpt2finetune/gpt-2/src/encoder.py\", line 116, in get_encoder\n",
            "    bpe_merges=bpe_merges,\n",
            "  File \"/content/drive/My Drive/gpt2finetune/gpt-2/src/encoder.py\", line 47, in __init__\n",
            "    self.byte_encoder = bytes_to_unicode()\n",
            "  File \"/content/drive/My Drive/gpt2finetune/gpt-2/src/encoder.py\", line 19, in bytes_to_unicode\n",
            "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"Â¡\"), ord(\"Â¬\")+1))+list(range(ord(\"Â®\"), ord(\"Ã¿\")+1))\n",
            "TypeError: ord() expected a character, but string of length 2 found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdOpenqWoYZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fbf1a9c-e67f-42d8-d50c-0821c29c822a"
      },
      "source": [
        "\n",
        "\n",
        "%cd /content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDpUckZ7TLfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd7c017-b0a4-44e9-d4d9-d77bb38fcccb"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t Dockerfile.gpu     LICENSE\t   requirements.txt  twremat\n",
            "CONTRIBUTORS.md  domains.txt\t    model_card.md  samples\n",
            "DEVELOPERS.md\t download_model.py  models\t   src\n",
            "Dockerfile.cpu\t encode.py\t    README.md\t   train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSiztPiaTVnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b365a55-40f5-4998-a27e-5138efbe4229"
      },
      "source": [
        "%cd models/124M/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/gpt2finetune/gpt-2/gpt-2/models/124M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq2iN0mCeoJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5edb42f-0c8f-43c6-9fb3-adda2c807c84"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t\t     model-1000.meta\n",
            "counter\t\t\t\t\t     model-1048.data-00000-of-00001\n",
            "encoder.json\t\t\t\t     model-1048.index\n",
            "events.out.tfevents.1627664019.2b40aee92a47  model.ckpt.data-00000-of-00001\n",
            "hparams.json\t\t\t\t     model.ckpt.index\n",
            "model-1000.data-00000-of-00001\t\t     model.ckpt.meta\n",
            "model-1000.index\t\t\t     vocab.bpe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8IibrpPeq74"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}