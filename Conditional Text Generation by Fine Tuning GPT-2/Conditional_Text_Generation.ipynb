{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conditional Text Generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM40r+Qmra1qM1Uh+EVhUK4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charithcherry/Text-completion-NLP/blob/master/Conditional%20Text%20Generation%20by%20Fine%20Tuning%20GPT-2/Conditional_Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4fMMIa3mQRc"
      },
      "source": [
        "**Finetuning GPT-2 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxLbs8zWlixu",
        "outputId": "375c3991-35b1-4409-b2db-92ab4bc5c31a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/gpt2finetune/gpt-2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/gpt2finetune/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjgni8HVSI1H"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR9wx9dzli1N",
        "outputId": "5600f370-242b-42a0-9051-5c32fd6dc016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/nshepperd/gpt-2\n",
        "%cd gpt-2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 435, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 435 (delta 19), reused 48 (delta 13), pack-reused 371\u001b[K\n",
            "Receiving objects: 100% (435/435), 4.48 MiB | 8.09 MiB/s, done.\n",
            "Resolving deltas: 100% (220/220), done.\n",
            "/content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qjb4_almoPJ",
        "outputId": "b3a9ffa1-6e54-46f4-b28b-1a07b4086d3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python download_model.py 124M\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 1.01Mit/s]                                                     \n",
            "Fetching encoder.json: 1.04Mit [00:00, 3.50Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 896kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:27, 18.3Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 6.11Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 1.88Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 1.83Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSK40h_vl6cP",
        "outputId": "17b7210b-3085-4981-a529-5e1cd724d184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5\n",
            "  Downloading regex-2017.04.05.tar.gz (601 kB)\n",
            "\u001b[K     |████████████████████████████████| 601 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting requests==2.21.0\n",
            "  Downloading requests-2.21.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.31.1\n",
            "  Downloading tqdm-4.31.1-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.8 MB/s \n",
            "\u001b[?25hCollecting toposort==1.5\n",
            "  Downloading toposort-1.5-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting idna<2.9,>=2.5\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Building wheels for collected packages: regex, fire\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp37-cp37m-linux_x86_64.whl size=534457 sha256=667e538c0f7564bce0dae4c6057e3e0bb56535132405ea8e49dc721b3d57d486\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/e8/a5/d4894e7ef29935f75c6074409ce8ca80a0271f0ce2a30da5d3\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=29e93c005057cda48e5399ec57ea700d7494f00cd59b7fee8f1ef0b994fc42de\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "Successfully built regex fire\n",
            "Installing collected packages: idna, tqdm, toposort, requests, regex, fire\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.21.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.31.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed fire-0.4.0 idna-2.8 regex-2017.4.5 requests-2.21.0 toposort-1.5 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNbl6WMSmfVy"
      },
      "source": [
        "!chmod 755 -R /content/drive/MyDrive/gpt2finetune/gpt-2\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUXEFrcRmfZR",
        "outputId": "38703661-ed3e-489e-fb8d-a6ca82944756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/drive/MyDrive/Corpus\n",
        "!export PYTHONIOENCODING=UTF-8\n",
        "%cd /content/drive/MyDrive/gpt2finetune/gpt-2"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Corpus\n",
            "/content/drive/MyDrive/gpt2finetune/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg453hYMm0Iv",
        "outputId": "866a80c5-9443-4cd0-895d-33bc472d4ed4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.0 \n",
        "!pip install ‘tensorflow-estimator<1.15.0rc0,>=1.14.0rc0’ — force-reinstall"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15.0\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 7.9 kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.34.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.17.3)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 52.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (57.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (4.6.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7553 sha256=32a8ab59297dc73fcd9704f50385188c074cb68fa64fded9da08dbb0c8fe5412\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires gast==0.4.0, but you have gast 0.2.2 which is incompatible.\n",
            "tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 1.15.0 which is incompatible.\n",
            "tensorflow 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 1.15.1 which is incompatible.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n",
            "/bin/bash: 1.15.0rc0,: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbEym1caWSAP",
        "outputId": "8ea4742b-c2c7-4054-b8df-29ee3de3a2c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riGBej9oYFkF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu1yTW5FnKVR",
        "outputId": "77524680-cd76-4c6d-a1d1-f9b2ace64d5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!PYTHONPATH=src ./train.py  --dataset /content/test.txt --model_name '124M'"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-30 16:53:18.845839: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-30 16:53:18.877299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-30 16:53:18.878052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-07-30 16:53:18.878374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-07-30 16:53:18.879661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-07-30 16:53:18.880810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-07-30 16:53:18.881184: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-07-30 16:53:18.882657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-07-30 16:53:18.883696: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-07-30 16:53:18.887041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-30 16:53:18.887163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-30 16:53:18.887828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-30 16:53:18.888419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-07-30 16:53:18.888808: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2021-07-30 16:53:18.893661: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
            "2021-07-30 16:53:18.893855: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c56d06e840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-30 16:53:18.893883: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-07-30 16:53:18.996440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-30 16:53:18.997266: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c56d06ef40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-07-30 16:53:18.997317: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-07-30 16:53:18.997487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-30 16:53:18.998121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-07-30 16:53:18.998186: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-07-30 16:53:18.998210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-07-30 16:53:18.998231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-07-30 16:53:18.998266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-07-30 16:53:18.998289: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-07-30 16:53:18.998309: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-07-30 16:53:18.998328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-07-30 16:53:18.998398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-30 16:53:18.999026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-30 16:53:18.999536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-07-30 16:53:18.999601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-07-30 16:53:19.000887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-30 16:53:19.000920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-07-30 16:53:19.000936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-07-30 16:53:19.001058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-30 16:53:19.001706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-30 16:53:19.002309: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-07-30 16:53:19.002352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt2finetune/gpt-2/gpt-2/src/sample.py:60: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt2finetune/gpt-2/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/gpt2finetune/gpt-2/gpt-2/src/sample.py:65: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "Using Adam optimizer\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n",
            "100% 1/1 [00:00<00:00, 4462.03it/s]\n",
            "dataset has 1769 tokens\n",
            "Training...\n",
            "2021-07-30 16:53:37.450159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "[1 | 6.04] loss=3.61 avg=3.61\n",
            "[2 | 6.44] loss=3.48 avg=3.54\n",
            "[3 | 6.85] loss=3.48 avg=3.52\n",
            "[4 | 7.26] loss=3.27 avg=3.46\n",
            "[5 | 7.67] loss=3.37 avg=3.44\n",
            "[6 | 8.08] loss=3.25 avg=3.41\n",
            "[7 | 8.49] loss=3.02 avg=3.35\n",
            "[8 | 8.89] loss=3.02 avg=3.31\n",
            "[9 | 9.30] loss=3.09 avg=3.28\n",
            "[10 | 9.71] loss=3.00 avg=3.25\n",
            "[11 | 10.12] loss=2.72 avg=3.20\n",
            "[12 | 10.53] loss=2.81 avg=3.17\n",
            "[13 | 10.94] loss=2.75 avg=3.13\n",
            "[14 | 11.36] loss=2.79 avg=3.11\n",
            "[15 | 11.77] loss=2.60 avg=3.07\n",
            "[16 | 12.18] loss=2.50 avg=3.03\n",
            "[17 | 12.59] loss=2.32 avg=2.99\n",
            "[18 | 13.00] loss=2.26 avg=2.94\n",
            "[19 | 13.41] loss=2.19 avg=2.90\n",
            "[20 | 13.83] loss=2.19 avg=2.86\n",
            "[21 | 14.24] loss=2.09 avg=2.82\n",
            "[22 | 14.65] loss=2.25 avg=2.79\n",
            "[23 | 15.06] loss=2.18 avg=2.76\n",
            "[24 | 15.47] loss=1.86 avg=2.72\n",
            "[25 | 15.88] loss=1.77 avg=2.68\n",
            "[26 | 16.29] loss=2.12 avg=2.65\n",
            "[27 | 16.70] loss=1.93 avg=2.62\n",
            "[28 | 17.11] loss=1.55 avg=2.58\n",
            "[29 | 17.52] loss=1.67 avg=2.54\n",
            "[30 | 17.93] loss=1.81 avg=2.51\n",
            "[31 | 18.34] loss=1.38 avg=2.47\n",
            "[32 | 18.76] loss=1.35 avg=2.43\n",
            "[33 | 19.17] loss=1.68 avg=2.40\n",
            "[34 | 19.58] loss=1.42 avg=2.37\n",
            "[35 | 19.99] loss=1.53 avg=2.34\n",
            "[36 | 20.40] loss=1.02 avg=2.30\n",
            "[37 | 20.82] loss=1.25 avg=2.27\n",
            "[38 | 21.23] loss=1.27 avg=2.23\n",
            "[39 | 21.64] loss=1.07 avg=2.20\n",
            "[40 | 22.05] loss=0.86 avg=2.16\n",
            "[41 | 22.46] loss=1.25 avg=2.13\n",
            "[42 | 22.88] loss=0.73 avg=2.09\n",
            "[43 | 23.29] loss=1.28 avg=2.07\n",
            "[44 | 23.70] loss=0.58 avg=2.03\n",
            "[45 | 24.11] loss=0.61 avg=1.99\n",
            "[46 | 24.53] loss=0.63 avg=1.95\n",
            "[47 | 24.94] loss=0.48 avg=1.91\n",
            "[48 | 25.35] loss=0.42 avg=1.87\n",
            "[49 | 25.77] loss=0.77 avg=1.84\n",
            "[50 | 26.18] loss=0.34 avg=1.81\n",
            "[51 | 26.59] loss=0.49 avg=1.77\n",
            "[52 | 27.01] loss=0.28 avg=1.74\n",
            "[53 | 27.42] loss=0.27 avg=1.70\n",
            "[54 | 27.84] loss=0.31 avg=1.67\n",
            "[55 | 28.25] loss=0.25 avg=1.63\n",
            "[56 | 28.67] loss=0.76 avg=1.61\n",
            "[57 | 29.08] loss=0.22 avg=1.58\n",
            "[58 | 29.49] loss=0.47 avg=1.56\n",
            "[59 | 29.91] loss=0.38 avg=1.53\n",
            "[60 | 30.32] loss=0.24 avg=1.50\n",
            "[61 | 30.74] loss=0.14 avg=1.47\n",
            "[62 | 31.15] loss=0.13 avg=1.44\n",
            "[63 | 31.56] loss=0.18 avg=1.42\n",
            "[64 | 31.98] loss=0.24 avg=1.39\n",
            "[65 | 32.39] loss=0.12 avg=1.36\n",
            "[66 | 32.81] loss=0.12 avg=1.34\n",
            "[67 | 33.22] loss=0.28 avg=1.32\n",
            "[68 | 33.63] loss=0.39 avg=1.30\n",
            "[69 | 34.05] loss=0.26 avg=1.28\n",
            "[70 | 34.47] loss=0.10 avg=1.25\n",
            "[71 | 34.88] loss=0.21 avg=1.23\n",
            "[72 | 35.30] loss=0.11 avg=1.21\n",
            "[73 | 35.72] loss=0.20 avg=1.19\n",
            "[74 | 36.13] loss=0.37 avg=1.18\n",
            "[75 | 36.55] loss=0.10 avg=1.16\n",
            "[76 | 36.97] loss=0.32 avg=1.14\n",
            "[77 | 37.38] loss=0.42 avg=1.13\n",
            "[78 | 37.80] loss=0.11 avg=1.11\n",
            "[79 | 38.22] loss=0.07 avg=1.09\n",
            "[80 | 38.63] loss=0.14 avg=1.07\n",
            "[81 | 39.05] loss=0.09 avg=1.06\n",
            "[82 | 39.46] loss=0.11 avg=1.04\n",
            "[83 | 39.88] loss=0.08 avg=1.02\n",
            "[84 | 40.30] loss=0.08 avg=1.01\n",
            "[85 | 40.71] loss=0.09 avg=0.99\n",
            "[86 | 41.13] loss=0.09 avg=0.97\n",
            "[87 | 41.55] loss=0.20 avg=0.96\n",
            "[88 | 41.97] loss=0.06 avg=0.95\n",
            "[89 | 42.39] loss=0.07 avg=0.93\n",
            "[90 | 42.80] loss=0.27 avg=0.92\n",
            "[91 | 43.22] loss=0.06 avg=0.90\n",
            "[92 | 43.64] loss=0.06 avg=0.89\n",
            "[93 | 44.06] loss=0.05 avg=0.88\n",
            "[94 | 44.47] loss=0.15 avg=0.87\n",
            "[95 | 44.89] loss=0.09 avg=0.85\n",
            "[96 | 45.32] loss=0.06 avg=0.84\n",
            "[97 | 45.73] loss=0.23 avg=0.83\n",
            "[98 | 46.15] loss=0.09 avg=0.82\n",
            "[99 | 46.57] loss=0.07 avg=0.81\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " common it seemed as if the characters themselves had been killed down the line. As for the plotting itself, the first two acts were as though the entire thing was an afterthought. In some ways, this is common with Simon Sandman's Sandman Adventures , where the overall point of the book was to send the reader on a journey of absolute and complete destruction. In this case, the book was to take place during the Fourth of July, which was an act of great religious and religious symbolism, which fulfilled Sandman's definition of holy war.\n",
            "\n",
            ", where the overall point of the book was to send the person or persons to act as spectators in act of worship, usually by directing the attention of soldiers to their military objects (e.g. towers, statues, etc.) and directing the attention of civilians to their civilian objects (such as lights, sounds, etc.) rather than their military ones.\n",
            "\n",
            "In some ways, the book was as if it were directed by actors\n",
            "\n",
            "The book was held in about the widest possible capacity by a line or two; for example, in the book's third act, the playing Beethoven appear behind the barometer reading John Taylor Swift (Taylor) and behind the barometer clock (Taylor) in act of worship. In the same way, the first act of the play portrayed the city of New York as if it were a movie. In the same way, the scene in the first act in which Taylor and his band were marching through the city singing and dancing was an act of act of worship.\n",
            "\n",
            "See also Celebrating An Act Of Religion ( censorship ) for the extent to which the act was religious.\n",
            "\n",
            ") for the extent to which the act was religious. In some ways, the book was like an artistic work; for example, the cover for Book One depicted the Prophet Muhammad (peace be upon him) riding a bicycle through the city, and the characters were using a typical book (e.g. A Clockwork Orange ) to represent the book. In Book Two, the characters were dancing and singing, and the effect was one of drawing ( drawing and moving with) the participant as they were, without regard to sex, race, religion, or person number.\n",
            "\n",
            ") for the extent to which the act was religious. In some ways, the book was like an artistic work; for example, the cover for Book One depicted the Prophet Muhammad (peace be upon him) riding a bicycle through the city, and the characters were using a typical book ( ) to represent the book. In Book Two, the characters were dancing and singing, and the effect was one of positioning (flailing, standing, etc.) to represent the place to the right of where the Prophet was, and the place to the left of where he was seated.\n",
            "\n",
            ") for the extent to which the act was religious. In many ways, the book was like an artistic work; for example, the cover for Book One depicted the Prophet Muhammad (peace be upon him) riding a bicycle through the city, and the characters were using a typical book ( ) to represent the book. In Book Two, the characters were dancing and singing, and the effect was one of positioning (flailing, standing, etc.) to represent the place to the right of where the Prophet was, and the place to the left of where he was seated.\n",
            "\n",
            "In other words, if the book portrayed religion in some way, such as by setting the stage or setting the tension in the scene, it was an act of religion. If the book portrayed it in some way by direct revelation (revealing anything about them or their plans) or by directing the attention of the audience (providing entertainment).\n",
            "\n",
            "Schein\n",
            "\n",
            "It is well-known by the standard Orthodox Jewish holidays of Yom Kippur and Hanukkah that an equivalent holiday is ascension. In Jewish law, God is highest in day and night, and He is the One who cometh to and from the Father and from the Son and from the Holy Spirit. In Jewish law, Adam and Eve are members of the Garden of Eden and are made members by the power of Law. In Jewish tradition, Adam and Eve had sex with God at an unspecified time between two other men (Gen. 1:6; 1 Cor. 4:11), and God revealed this to Adam through the power of the Prophets, who were mentioned in the Garden of Eden (1 Cor. 9:1–10). In Judaism, the Lord's Supper is the Passover table and altar (Elohim) are the Sabbaths (the Excesses) between meals which start at an unspecified time in the morning (Ex. 1:7; 1 Chron. 19:18; 1 Tim. 3:17; Titus 1:11; 1 Pet. 1:5). In Jewish law, the day and night of sex are considered the week (Zohar) and, in Jewish law, Adam and Eve could enter into sex at an unspecified\n",
            "\n",
            "[100 | 58.88] loss=0.05 avg=0.79\n",
            "[101 | 59.29] loss=0.07 avg=0.78\n",
            "[102 | 59.71] loss=0.09 avg=0.77\n",
            "[103 | 60.13] loss=0.05 avg=0.76\n",
            "[104 | 60.55] loss=0.08 avg=0.75\n",
            "[105 | 60.97] loss=0.06 avg=0.74\n",
            "[106 | 61.39] loss=0.06 avg=0.73\n",
            "[107 | 61.81] loss=0.04 avg=0.72\n",
            "[108 | 62.23] loss=0.15 avg=0.71\n",
            "[109 | 62.65] loss=0.14 avg=0.70\n",
            "[110 | 63.07] loss=0.08 avg=0.69\n",
            "[111 | 63.49] loss=0.04 avg=0.68\n",
            "[112 | 63.91] loss=0.04 avg=0.67\n",
            "[113 | 64.33] loss=0.06 avg=0.66\n",
            "[114 | 64.75] loss=0.06 avg=0.66\n",
            "[115 | 65.17] loss=0.07 avg=0.65\n",
            "[116 | 65.59] loss=0.05 avg=0.64\n",
            "[117 | 66.01] loss=0.05 avg=0.63\n",
            "[118 | 66.43] loss=0.04 avg=0.62\n",
            "[119 | 66.86] loss=0.04 avg=0.61\n",
            "[120 | 67.27] loss=0.04 avg=0.60\n",
            "[121 | 67.70] loss=0.04 avg=0.60\n",
            "[122 | 68.12] loss=0.03 avg=0.59\n",
            "[123 | 68.54] loss=0.04 avg=0.58\n",
            "[124 | 68.96] loss=0.04 avg=0.57\n",
            "[125 | 69.38] loss=0.05 avg=0.57\n",
            "[126 | 69.80] loss=0.04 avg=0.56\n",
            "[127 | 70.23] loss=0.02 avg=0.55\n",
            "[128 | 70.65] loss=0.19 avg=0.55\n",
            "[129 | 71.07] loss=0.03 avg=0.54\n",
            "[130 | 71.49] loss=0.04 avg=0.53\n",
            "[131 | 71.91] loss=0.04 avg=0.53\n",
            "[132 | 72.34] loss=0.03 avg=0.52\n",
            "[133 | 72.76] loss=0.08 avg=0.51\n",
            "[134 | 73.18] loss=0.03 avg=0.51\n",
            "[135 | 73.60] loss=0.03 avg=0.50\n",
            "[136 | 74.03] loss=0.04 avg=0.49\n",
            "[137 | 74.45] loss=0.03 avg=0.49\n",
            "[138 | 74.87] loss=0.10 avg=0.48\n",
            "[139 | 75.29] loss=0.06 avg=0.48\n",
            "[140 | 75.72] loss=0.04 avg=0.47\n",
            "[141 | 76.14] loss=0.06 avg=0.47\n",
            "[142 | 76.56] loss=0.03 avg=0.46\n",
            "[143 | 76.99] loss=0.03 avg=0.45\n",
            "[144 | 77.41] loss=0.04 avg=0.45\n",
            "[145 | 77.83] loss=0.04 avg=0.44\n",
            "[146 | 78.26] loss=0.03 avg=0.44\n",
            "[147 | 78.68] loss=0.02 avg=0.43\n",
            "[148 | 79.11] loss=0.03 avg=0.43\n",
            "[149 | 79.53] loss=0.04 avg=0.42\n",
            "[150 | 79.96] loss=0.04 avg=0.42\n",
            "[151 | 80.38] loss=0.04 avg=0.41\n",
            "[152 | 80.80] loss=0.03 avg=0.41\n",
            "[153 | 81.23] loss=0.03 avg=0.40\n",
            "[154 | 81.65] loss=0.03 avg=0.40\n",
            "[155 | 82.07] loss=0.03 avg=0.39\n",
            "[156 | 82.50] loss=0.03 avg=0.39\n",
            "[157 | 82.92] loss=0.04 avg=0.38\n",
            "[158 | 83.35] loss=0.04 avg=0.38\n",
            "[159 | 83.77] loss=0.04 avg=0.38\n",
            "[160 | 84.19] loss=0.06 avg=0.37\n",
            "[161 | 84.62] loss=0.04 avg=0.37\n",
            "[162 | 85.04] loss=0.04 avg=0.36\n",
            "[163 | 85.47] loss=0.07 avg=0.36\n",
            "[164 | 85.89] loss=0.03 avg=0.36\n",
            "[165 | 86.32] loss=0.10 avg=0.35\n",
            "[166 | 86.74] loss=0.04 avg=0.35\n",
            "[167 | 87.17] loss=0.05 avg=0.35\n",
            "[168 | 87.60] loss=0.04 avg=0.34\n",
            "[169 | 88.02] loss=0.03 avg=0.34\n",
            "[170 | 88.45] loss=0.05 avg=0.33\n",
            "[171 | 88.87] loss=0.11 avg=0.33\n",
            "[172 | 89.30] loss=0.04 avg=0.33\n",
            "[173 | 89.72] loss=0.05 avg=0.32\n",
            "[174 | 90.14] loss=0.03 avg=0.32\n",
            "[175 | 90.57] loss=0.03 avg=0.32\n",
            "[176 | 91.00] loss=0.03 avg=0.31\n",
            "[177 | 91.42] loss=0.05 avg=0.31\n",
            "[178 | 91.85] loss=0.04 avg=0.31\n",
            "[179 | 92.28] loss=0.05 avg=0.30\n",
            "[180 | 92.71] loss=0.02 avg=0.30\n",
            "[181 | 93.13] loss=0.07 avg=0.30\n",
            "[182 | 93.56] loss=0.03 avg=0.30\n",
            "[183 | 93.98] loss=0.08 avg=0.29\n",
            "[184 | 94.41] loss=0.03 avg=0.29\n",
            "[185 | 94.84] loss=0.03 avg=0.29\n",
            "[186 | 95.26] loss=0.04 avg=0.28\n",
            "[187 | 95.69] loss=0.03 avg=0.28\n",
            "[188 | 96.12] loss=0.04 avg=0.28\n",
            "[189 | 96.54] loss=0.04 avg=0.27\n",
            "[190 | 96.97] loss=0.05 avg=0.27\n",
            "[191 | 97.39] loss=0.03 avg=0.27\n",
            "[192 | 97.82] loss=0.02 avg=0.27\n",
            "[193 | 98.25] loss=0.03 avg=0.26\n",
            "[194 | 98.67] loss=0.04 avg=0.26\n",
            "[195 | 99.10] loss=0.03 avg=0.26\n",
            "[196 | 99.53] loss=0.03 avg=0.26\n",
            "[197 | 99.95] loss=0.04 avg=0.25\n",
            "[198 | 100.38] loss=0.03 avg=0.25\n",
            "[199 | 100.80] loss=0.03 avg=0.25\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " in the midst of an all too common conversation of wealth and power. In many scenes, Martha Stewart appeared in awe at the wealth and power of the crowd. In one scene, Martha Stewart appeared visibly emotional with the crowd and praised them for their character portrayal. In another scene, Martha Stewart appeared visibly somber with the crowd and praised them for their performance as Maajid Nawaz in the popular show and for their portrayal of Al-Qaeda leader Osama bin Laden. In all, Martha Stewart appeared visibly somber with the crowd and praised them for their performance as the heroines in the popular film.\n",
            "\n",
            "The play was well interpreted by all whom were involved. Steven Wrentmore, the Director, kept the 1920 cemeteries which had a more subdued feel to them than the previous two films in the series. Also, during the play's play much more lighting was placed on the floor than on the walls. Also, during the play's play actors were more often than not wearing makeup or a different makeup job appeared on screen than any of the actors in the previous two productions.\n",
            "\n",
            "The lighting throughout the play was overall with the shadows casting more shadow and the lighting plants bringing more light to the scene, while still maintaining the 1920 feel to the stage. Every detail about the layout of the stage was present except for the raised bleachers and wings being present throughout the play. The lighting throughout the play was accomplished with an extensive lighting area built into the wall and above deck that contained the television, the well lit restaurant and the home entertainment center. The entire space was well lit throughout the play; the stage area was well lit and the foliage wason the stage. the space was well lit; the area was well lit, the foliage wason the wall, and the play took place within a very small space; the entrance to the home entertainment center was very small; the entire space was within about an acre of space; and the outside of the home entertainment center was approximately an inch further away than the actual home. The thirty step sequence in the featured movie was an example of an example night of the metered market line where a spacey substance occupy more space than the light or darkness required to be occupied. The scene was fully filmed with the space detail understated.\n",
            "\n",
            "The location all had the feel of a location, the landmass itself emphasized the space, and the detail in detail was almost certainly taken from the stage. All of the detail took place within the sight of audience members or other visible spectators. The detail inside the home represented great detail and amount of detail did not do the location appear small. All of the detail in the home exceeded expectation. The entire scene was well choreographed, all scenes within the first ten minutes of filming high definition, they took place in the same space as the first scene in that order.\n",
            "\n",
            "The place itself was likable by its plainness; the very first scene the very first person to appear took place there. The entire scene was likable at its core; the very first person to appear it waslessly awkward into explaining why he was supposed to be present until the very end. When the second person was more awkward than understandable why they were more so they had fewer opportunities to infer why they were made more awkward. The second person was even more awkward than the first; the reason why the first was even was because he made more of an effort to be awkward than the second person. The awkward nature of the first person made it almost comical. The awkwardness of the first laugh caused the second laugh to be much more awkward than the first cause for doing the earlier laugh more often than the later one. The awkwardness of the game of hide and seek made it nearly comical to use the first person to the bitter end. The awkwardness of the family laughter made it almost comical to use the first person to the bitter end.\n",
            "\n",
            "The location manner was likable because it was simply at the place where the sarcasm or bluff was made, the very first action shown was an instance of, the very first place that could not be learned was the earth. The very first place could not be learned, such as the lake or the fields. The very first place could not be grown, such as the fields. The very first place could not be operated on, such as the box office.\n",
            "\n",
            "The environment manner was so amoral that it was almost sexual. The wife justinaclaimed it was because she was so looked at she could not be bothered to do anything about it. The wifeplayed it cool by playing it direct she had to do it on her own. The wifeplayed it inconsiderate by playing it clever by doing anything about it. The innocent play it malicious by doing anything about it just.\n",
            "\n",
            "The food was ambery dotted with vegetable shortening and seasonings such as canteen wasabi and celery came with the same as well as bread wasabi and mayo were part of the entree. The canteen was for sale but the isahki\n",
            "\n",
            "[200 | 111.13] loss=0.02 avg=0.25\n",
            "[201 | 111.56] loss=0.03 avg=0.24\n",
            "[202 | 111.99] loss=0.03 avg=0.24\n",
            "[203 | 112.42] loss=0.02 avg=0.24\n",
            "[204 | 112.85] loss=0.07 avg=0.24\n",
            "[205 | 113.28] loss=0.01 avg=0.23\n",
            "[206 | 113.71] loss=0.02 avg=0.23\n",
            "[207 | 114.13] loss=0.02 avg=0.23\n",
            "[208 | 114.56] loss=0.04 avg=0.23\n",
            "[209 | 114.99] loss=0.02 avg=0.22\n",
            "[210 | 115.42] loss=0.03 avg=0.22\n",
            "[211 | 115.85] loss=0.02 avg=0.22\n",
            "[212 | 116.28] loss=0.02 avg=0.22\n",
            "[213 | 116.70] loss=0.04 avg=0.22\n",
            "[214 | 117.13] loss=0.03 avg=0.21\n",
            "[215 | 117.55] loss=0.02 avg=0.21\n",
            "[216 | 117.98] loss=0.02 avg=0.21\n",
            "[217 | 118.41] loss=0.03 avg=0.21\n",
            "[218 | 118.84] loss=0.05 avg=0.21\n",
            "[219 | 119.27] loss=0.02 avg=0.20\n",
            "[220 | 119.70] loss=0.02 avg=0.20\n",
            "[221 | 120.13] loss=0.03 avg=0.20\n",
            "[222 | 120.55] loss=0.02 avg=0.20\n",
            "[223 | 120.99] loss=0.02 avg=0.20\n",
            "[224 | 121.42] loss=0.02 avg=0.19\n",
            "[225 | 121.84] loss=0.04 avg=0.19\n",
            "[226 | 122.27] loss=0.03 avg=0.19\n",
            "[227 | 122.70] loss=0.03 avg=0.19\n",
            "[228 | 123.13] loss=0.02 avg=0.19\n",
            "[229 | 123.56] loss=0.02 avg=0.18\n",
            "[230 | 123.99] loss=0.02 avg=0.18\n",
            "[231 | 124.43] loss=0.05 avg=0.18\n",
            "[232 | 124.85] loss=0.02 avg=0.18\n",
            "[233 | 125.28] loss=0.04 avg=0.18\n",
            "[234 | 125.71] loss=0.02 avg=0.18\n",
            "[235 | 126.14] loss=0.04 avg=0.17\n",
            "[236 | 126.58] loss=0.02 avg=0.17\n",
            "[237 | 127.01] loss=0.05 avg=0.17\n",
            "[238 | 127.44] loss=0.02 avg=0.17\n",
            "[239 | 127.87] loss=0.03 avg=0.17\n",
            "[240 | 128.30] loss=0.02 avg=0.17\n",
            "[241 | 128.73] loss=0.02 avg=0.16\n",
            "[242 | 129.16] loss=0.01 avg=0.16\n",
            "[243 | 129.59] loss=0.02 avg=0.16\n",
            "[244 | 130.02] loss=0.02 avg=0.16\n",
            "[245 | 130.45] loss=0.02 avg=0.16\n",
            "[246 | 130.88] loss=0.03 avg=0.16\n",
            "[247 | 131.32] loss=0.02 avg=0.16\n",
            "[248 | 131.75] loss=0.03 avg=0.15\n",
            "[249 | 132.18] loss=0.02 avg=0.15\n",
            "[250 | 132.61] loss=0.02 avg=0.15\n",
            "[251 | 133.04] loss=0.01 avg=0.15\n",
            "[252 | 133.47] loss=0.01 avg=0.15\n",
            "[253 | 133.90] loss=0.03 avg=0.15\n",
            "[254 | 134.34] loss=0.03 avg=0.15\n",
            "[255 | 134.77] loss=0.04 avg=0.14\n",
            "[256 | 135.20] loss=0.02 avg=0.14\n",
            "[257 | 135.64] loss=0.01 avg=0.14\n",
            "[258 | 136.07] loss=0.02 avg=0.14\n",
            "[259 | 136.50] loss=0.03 avg=0.14\n",
            "[260 | 136.93] loss=0.03 avg=0.14\n",
            "[261 | 137.36] loss=0.02 avg=0.14\n",
            "[262 | 137.79] loss=0.03 avg=0.14\n",
            "[263 | 138.23] loss=0.02 avg=0.13\n",
            "[264 | 138.66] loss=0.01 avg=0.13\n",
            "[265 | 139.09] loss=0.02 avg=0.13\n",
            "[266 | 139.52] loss=0.02 avg=0.13\n",
            "[267 | 139.96] loss=0.02 avg=0.13\n",
            "[268 | 140.39] loss=0.02 avg=0.13\n",
            "[269 | 140.82] loss=0.04 avg=0.13\n",
            "[270 | 141.26] loss=0.02 avg=0.13\n",
            "[271 | 141.69] loss=0.01 avg=0.13\n",
            "[272 | 142.12] loss=0.04 avg=0.12\n",
            "[273 | 142.55] loss=0.02 avg=0.12\n",
            "[274 | 142.99] loss=0.03 avg=0.12\n",
            "[275 | 143.42] loss=0.01 avg=0.12\n",
            "[276 | 143.85] loss=0.02 avg=0.12\n",
            "[277 | 144.29] loss=0.03 avg=0.12\n",
            "[278 | 144.72] loss=0.02 avg=0.12\n",
            "[279 | 145.15] loss=0.02 avg=0.12\n",
            "[280 | 145.58] loss=0.01 avg=0.12\n",
            "[281 | 146.02] loss=0.02 avg=0.11\n",
            "[282 | 146.45] loss=0.02 avg=0.11\n",
            "[283 | 146.88] loss=0.02 avg=0.11\n",
            "[284 | 147.32] loss=0.02 avg=0.11\n",
            "[285 | 147.75] loss=0.01 avg=0.11\n",
            "[286 | 148.18] loss=0.02 avg=0.11\n",
            "[287 | 148.61] loss=0.03 avg=0.11\n",
            "[288 | 149.05] loss=0.02 avg=0.11\n",
            "[289 | 149.48] loss=0.03 avg=0.11\n",
            "[290 | 149.91] loss=0.02 avg=0.11\n",
            "[291 | 150.35] loss=0.01 avg=0.11\n",
            "[292 | 150.78] loss=0.02 avg=0.10\n",
            "[293 | 151.21] loss=0.03 avg=0.10\n",
            "[294 | 151.65] loss=0.01 avg=0.10\n",
            "[295 | 152.08] loss=0.02 avg=0.10\n",
            "[296 | 152.52] loss=0.04 avg=0.10\n",
            "[297 | 152.95] loss=0.07 avg=0.10\n",
            "[298 | 153.38] loss=0.02 avg=0.10\n",
            "[299 | 153.81] loss=0.03 avg=0.10\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " to the ground when the player was on the roof. In other words, the more players on the ground, the angrier was the game.\n",
            "\n",
            "The game was well cast, the entire Bliss family did a great job showing how overly dramatic and deceitful the family had become. Each actor portrayed their character accurately; there were no standouts that didn’t match the character. Each visitor in the first act seemed to be feasible as far as the possibility of a relationship was concerned. All of the family members acted genuine. There was one actor who stood out as a perfect fit for his character. Taylor Rascher played Simon Bliss and played him perfectly. Rascher’s character Simon was a young man who was dramatic and romantic so much so it was almost to the point of ridiculousness. Rascher stole the show in the first act when he was romancing with Michelle Luz, who plays Myra Arundel. Rascher was displaying his love for Michelle Luz (Myra) in the most dramatic of fashions; he was playing the Bliss’ game of pretending to be in complete love with someone and then a moment later change his mind. Rascher was proclaiming his love with elegant speeches and coddling up next to her and eventually kissing her. Rascher made this scene particularly hilarious because he was completely over the top in typical Bliss fashion. Of course, all of this was for naught because Luz ended up kissing Joe Hubbard’s character David Bliss in act two and also Rascher proclaimed his engagement to Caitlin Stagemoller’s character, Jackie Coryton. Rascher made his voice more shrill and audible to appear to be more dramatic and create more attention for himself. In the same way, Rascher used grander gestures with his arms (flailing, waving, etc.) to cause a more dramatic effect.\n",
            "\n",
            "The play was well interpreted by all whom were involved. Steven Wrentmore, the Director, kept the 1920’s feel by dressing in all 1920’s costumes and everyone spoke as if they were living at the time. Michelle Bisbee, the scene designer, made the inside of the home appear 1920’s because everything was grand. The Bliss’ home was grand with the spiral staircase, the very large backdoors, and the eloquent piano. The actors’ mannerisms seemed like they were portraying a silent film. In older movies, actors seemed very dramatic and had flamboyant actions to prove so; the actors in Hay Fever shared the same feel for the dramatics. As far as Stephen Wrentmore’s directing goes, he did an excellent job. The scene when Chris Karl (Richard) and Caitlin Stegemoller (Jackie) enter and are left alone to make small talk with each other is the best pertaining to directing. The two actors used the entire stage in this scene and were very awkward with one another. This was Wrentmore’s doing because you could tell he had a vision for this scene in particular because it seemed very crisp and well rehearsed. The actors played it perfect with the excessively long pauses in their awkward small talk that the crowd was laughing through the entire scene. It appeared that Wrentmore instructed the actors, to keep their pauses longer than natural to heighten the awkward tension in the scene, which made it brilliant.\n",
            "\n",
            "The blocking throughout the play worked with the floor plan very well. All of the blocking worked seamlessly; the actors were never out of sight or in awkward positioning (ex. turned around, talking to someone behind them while face forward, etc.) even during the second act in the first scene while all eight actors were on set. One part of the set that stood out was the staircase, it is obviously very large, but the way Owen Virgin followed Megan Davis up the stairs was seamless. They both walked up the stairs with footsteps I unison, and Owen Virgin was so focused on every detail of Davis, it almost screamed out how much he was infatuated with her.\n",
            "\n",
            "The artistic intent of this production was to entertain, and it fulfilled that intent completely. The entire audience was laughing during most of the production, I was even laughing out loud, which doesn’t happen very often. Every interaction between the characters was comical at one point during the production. An example of this playing out would be in the second act when Rascher busts through the door and proclaims his engagement. The only purpose of this is to entertain and entertain it did. The actors seemed natural moving along with their blocking and engaging with each other on stage. There was no point at which it was confusing why someone moved here or there, every movement made sense.\n",
            "\n",
            "The overall mood that was portrayed by the combination of lighting, sound, set, and costumes was very light and cheerful; at no point did the mood drop to something darker or saddening. This is common with many comedies because it becomes hard to laugh if the overall mood is down\n",
            "\n",
            "[300 | 164.51] loss=0.01 avg=0.10\n",
            "[301 | 164.95] loss=0.03 avg=0.10\n",
            "[302 | 165.39] loss=0.02 avg=0.10\n",
            "[303 | 165.82] loss=0.02 avg=0.10\n",
            "[304 | 166.25] loss=0.03 avg=0.09\n",
            "[305 | 166.69] loss=0.01 avg=0.09\n",
            "[306 | 167.13] loss=0.01 avg=0.09\n",
            "[307 | 167.56] loss=0.02 avg=0.09\n",
            "[308 | 168.00] loss=0.01 avg=0.09\n",
            "[309 | 168.43] loss=0.02 avg=0.09\n",
            "[310 | 168.87] loss=0.01 avg=0.09\n",
            "[311 | 169.30] loss=0.02 avg=0.09\n",
            "[312 | 169.73] loss=0.02 avg=0.09\n",
            "[313 | 170.17] loss=0.02 avg=0.09\n",
            "[314 | 170.60] loss=0.01 avg=0.09\n",
            "[315 | 171.04] loss=0.01 avg=0.09\n",
            "[316 | 171.47] loss=0.02 avg=0.09\n",
            "[317 | 171.91] loss=0.02 avg=0.09\n",
            "[318 | 172.35] loss=0.02 avg=0.08\n",
            "[319 | 172.78] loss=0.02 avg=0.08\n",
            "[320 | 173.22] loss=0.01 avg=0.08\n",
            "[321 | 173.66] loss=0.01 avg=0.08\n",
            "[322 | 174.09] loss=0.01 avg=0.08\n",
            "[323 | 174.53] loss=0.04 avg=0.08\n",
            "[324 | 174.96] loss=0.02 avg=0.08\n",
            "[325 | 175.40] loss=0.02 avg=0.08\n",
            "[326 | 175.84] loss=0.02 avg=0.08\n",
            "[327 | 176.27] loss=0.01 avg=0.08\n",
            "[328 | 176.71] loss=0.02 avg=0.08\n",
            "[329 | 177.14] loss=0.01 avg=0.08\n",
            "[330 | 177.58] loss=0.01 avg=0.08\n",
            "[331 | 178.02] loss=0.03 avg=0.08\n",
            "[332 | 178.46] loss=0.02 avg=0.08\n",
            "[333 | 178.89] loss=0.02 avg=0.07\n",
            "[334 | 179.33] loss=0.02 avg=0.07\n",
            "[335 | 179.77] loss=0.02 avg=0.07\n",
            "[336 | 180.20] loss=0.02 avg=0.07\n",
            "[337 | 180.64] loss=0.01 avg=0.07\n",
            "[338 | 181.07] loss=0.02 avg=0.07\n",
            "[339 | 181.51] loss=0.03 avg=0.07\n",
            "[340 | 181.94] loss=0.02 avg=0.07\n",
            "[341 | 182.38] loss=0.01 avg=0.07\n",
            "[342 | 182.81] loss=0.01 avg=0.07\n",
            "[343 | 183.25] loss=0.01 avg=0.07\n",
            "[344 | 183.69] loss=0.03 avg=0.07\n",
            "[345 | 184.12] loss=0.02 avg=0.07\n",
            "[346 | 184.56] loss=0.02 avg=0.07\n",
            "[347 | 185.00] loss=0.02 avg=0.07\n",
            "[348 | 185.43] loss=0.01 avg=0.07\n",
            "[349 | 185.87] loss=0.02 avg=0.07\n",
            "[350 | 186.31] loss=0.01 avg=0.07\n",
            "[351 | 186.74] loss=0.01 avg=0.06\n",
            "[352 | 187.18] loss=0.01 avg=0.06\n",
            "[353 | 187.62] loss=0.03 avg=0.06\n",
            "[354 | 188.05] loss=0.02 avg=0.06\n",
            "[355 | 188.49] loss=0.01 avg=0.06\n",
            "[356 | 188.92] loss=0.03 avg=0.06\n",
            "[357 | 189.36] loss=0.02 avg=0.06\n",
            "[358 | 189.80] loss=0.01 avg=0.06\n",
            "[359 | 190.23] loss=0.03 avg=0.06\n",
            "[360 | 190.67] loss=0.02 avg=0.06\n",
            "[361 | 191.11] loss=0.03 avg=0.06\n",
            "[362 | 191.55] loss=0.01 avg=0.06\n",
            "[363 | 191.98] loss=0.02 avg=0.06\n",
            "[364 | 192.42] loss=0.02 avg=0.06\n",
            "[365 | 192.86] loss=0.01 avg=0.06\n",
            "[366 | 193.30] loss=0.03 avg=0.06\n",
            "[367 | 193.73] loss=0.01 avg=0.06\n",
            "[368 | 194.17] loss=0.02 avg=0.06\n",
            "[369 | 194.61] loss=0.01 avg=0.06\n",
            "[370 | 195.05] loss=0.03 avg=0.06\n",
            "[371 | 195.48] loss=0.02 avg=0.06\n",
            "[372 | 195.92] loss=0.02 avg=0.06\n",
            "[373 | 196.36] loss=0.01 avg=0.06\n",
            "[374 | 196.79] loss=0.01 avg=0.06\n",
            "[375 | 197.23] loss=0.02 avg=0.05\n",
            "[376 | 197.67] loss=0.01 avg=0.05\n",
            "[377 | 198.11] loss=0.02 avg=0.05\n",
            "[378 | 198.55] loss=0.02 avg=0.05\n",
            "[379 | 198.98] loss=0.01 avg=0.05\n",
            "[380 | 199.42] loss=0.01 avg=0.05\n",
            "[381 | 199.85] loss=0.01 avg=0.05\n",
            "[382 | 200.29] loss=0.02 avg=0.05\n",
            "[383 | 200.73] loss=0.02 avg=0.05\n",
            "[384 | 201.17] loss=0.01 avg=0.05\n",
            "[385 | 201.61] loss=0.02 avg=0.05\n",
            "[386 | 202.05] loss=0.01 avg=0.05\n",
            "[387 | 202.49] loss=0.02 avg=0.05\n",
            "[388 | 202.92] loss=0.01 avg=0.05\n",
            "[389 | 203.36] loss=0.02 avg=0.05\n",
            "[390 | 203.80] loss=0.01 avg=0.05\n",
            "[391 | 204.24] loss=0.02 avg=0.05\n",
            "[392 | 204.68] loss=0.01 avg=0.05\n",
            "[393 | 205.12] loss=0.02 avg=0.05\n",
            "[394 | 205.56] loss=0.01 avg=0.05\n",
            "[395 | 206.00] loss=0.01 avg=0.05\n",
            "[396 | 206.43] loss=0.03 avg=0.05\n",
            "[397 | 206.87] loss=0.02 avg=0.05\n",
            "[398 | 207.31] loss=0.02 avg=0.05\n",
            "[399 | 207.75] loss=0.01 avg=0.05\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            ".\n",
            "\n",
            "The play was well cast, the entire Bliss family did a great job showing how overly dramatic and deceitful the family had become. Each actor portrayed their character accurately; there were no standouts that didn’t match the character. Each visitor in the first act seemed to be feasible as far as the possibility was concerned. All of the family members acted genuine. There was one actor who stood out as a perfect fit for his character. Taylor Rascher played Simon Bliss and played him perfectly. Rascher’s character Simon was a young man who was dramatic and romantic so much so it was almost to the point of ridiculousness. Rascher stole the show in the first act when he was romancing with Michelle Luz, who plays Myra Arundel. Rascher was displaying his love for Michelle Luz (Myra) in the most dramatic of fashions; he was playing the Bliss’ game of pretending to be in complete love with someone and then a moment later change his mind. Rascher was proclaiming his love with elegant speeches and coddling up next to her and eventually kissing her. Rascher made this scene particularly hilarious because he was completely over the top in typical Bliss fashion. Of course, all of this was for naught because Luz ended up kissing Joe Hubbard’s character David Bliss in act two and also Rascher proclaimed his engagement to Caitlin Stagemoller’s character, Jackie Coryton. Rascher made his voice more shrill and audible to appear to be more dramatic and create more attention for himself. In the same way, Rascher used grander gestures with his arms (flailing, waving, etc.) to cause a more dramatic effect.\n",
            "\n",
            "The play was well interpreted by all whom were involved. Steven Wrentmore, the Director, kept the 1920’s feel by dressing in all 1920’s costumes and everyone spoke as if they were living at the time. Michelle Bisbee, the scene designer, made the inside of the home appear 1920’s because everything was grand. The Bliss’ home was grand with the spiral staircase, the very large backdoors, and the eloquent piano. The actors’ mannerisms seemed like they were portraying a silent film. In older movies, actors seemed very dramatic and had flamboyant actions to prove so; the actors in Hay Fever shared the same feel for the dramatics. As far as Stephen Wrentmore’s directing goes, he did an excellent job. The scene when Chris Karl (Richard) and Caitlin Stegemoller (Jackie) enter and are left alone to make small talk with each other is the best pertaining to directing. The two actors used the entire stage in this scene and were very awkward with one another. This was Wrentmore’s doing because you could tell he had a vision for this scene in particular because it seemed very crisp and well rehearsed. The actors played it perfect with the excessively long pauses in their awkward small talk that the crowd was laughing through the entire scene. It appeared that Wrentmore instructed the actors, to keep their pauses longer than natural to heighten the awkward tension in the scene, which made it brilliant.\n",
            "\n",
            "The blocking throughout the play worked with the floor plan very well. All of the blocking worked seamlessly; the actors were never out of sight or in awkward positioning (ex. turned around, talking to someone behind them while face forward, etc.) even during the second act in the first scene while all eight actors were on set. One part of the set that stood out was the staircase, it is obviously very large, but the way Owen Virgin followed Megan Davis up the stairs was seamless. They both walked up the stairs with footsteps I unison, and Owen Virgin was so focused on every detail of Davis, it almost screamed out how much he was infatuated with her.\n",
            "\n",
            "The artistic intent of this production was to entertain, and it fulfilled that intent completely. The entire audience was laughing during most of the production, I was even laughing out loud, which doesn’t happen very often. Every interaction between the characters was comical at one point during the production. An example of this playing out would be in the second act when Rascher busts through the door and proclaims his engagement. The only purpose of this is to entertain and entertain it did. The actors seemed natural moving along with their blocking and engaging with each other on stage. There was no point at which it was confusing why someone moved here or there, every movement made sense.\n",
            "\n",
            "The overall mood that was portrayed by the combination of lighting, sound, set, and costumes was very light and cheerful; at no point did the mood drop to something darker or saddening. This is common with many comedies because it becomes hard to laugh if the overall mood is down and dreary. The theatre space was very personal. First of all, it takes place in someone’s home so it is immediately personal.\n",
            "\n",
            "[400 | 218.75] loss=0.03 avg=0.05\n",
            "[401 | 219.19] loss=0.01 avg=0.05\n",
            "[402 | 219.63] loss=0.02 avg=0.05\n",
            "[403 | 220.08] loss=0.02 avg=0.05\n",
            "[404 | 220.51] loss=0.02 avg=0.04\n",
            "[405 | 220.96] loss=0.02 avg=0.04\n",
            "[406 | 221.40] loss=0.01 avg=0.04\n",
            "[407 | 221.84] loss=0.01 avg=0.04\n",
            "[408 | 222.28] loss=0.02 avg=0.04\n",
            "[409 | 222.72] loss=0.01 avg=0.04\n",
            "[410 | 223.16] loss=0.01 avg=0.04\n",
            "[411 | 223.60] loss=0.01 avg=0.04\n",
            "[412 | 224.04] loss=0.02 avg=0.04\n",
            "[413 | 224.48] loss=0.02 avg=0.04\n",
            "[414 | 224.92] loss=0.01 avg=0.04\n",
            "[415 | 225.36] loss=0.02 avg=0.04\n",
            "[416 | 225.80] loss=0.02 avg=0.04\n",
            "[417 | 226.24] loss=0.03 avg=0.04\n",
            "[418 | 226.68] loss=0.01 avg=0.04\n",
            "[419 | 227.13] loss=0.02 avg=0.04\n",
            "[420 | 227.57] loss=0.01 avg=0.04\n",
            "[421 | 228.01] loss=0.01 avg=0.04\n",
            "[422 | 228.45] loss=0.01 avg=0.04\n",
            "[423 | 228.89] loss=0.02 avg=0.04\n",
            "[424 | 229.33] loss=0.01 avg=0.04\n",
            "[425 | 229.77] loss=0.01 avg=0.04\n",
            "[426 | 230.21] loss=0.01 avg=0.04\n",
            "[427 | 230.66] loss=0.01 avg=0.04\n",
            "[428 | 231.10] loss=0.02 avg=0.04\n",
            "[429 | 231.54] loss=0.01 avg=0.04\n",
            "[430 | 231.98] loss=0.02 avg=0.04\n",
            "[431 | 232.42] loss=0.02 avg=0.04\n",
            "[432 | 232.86] loss=0.02 avg=0.04\n",
            "[433 | 233.30] loss=0.01 avg=0.04\n",
            "[434 | 233.75] loss=0.02 avg=0.04\n",
            "[435 | 234.19] loss=0.01 avg=0.04\n",
            "[436 | 234.63] loss=0.01 avg=0.04\n",
            "[437 | 235.07] loss=0.01 avg=0.04\n",
            "[438 | 235.51] loss=0.02 avg=0.04\n",
            "[439 | 235.95] loss=0.01 avg=0.04\n",
            "[440 | 236.39] loss=0.02 avg=0.04\n",
            "[441 | 236.84] loss=0.01 avg=0.04\n",
            "[442 | 237.28] loss=0.01 avg=0.04\n",
            "[443 | 237.72] loss=0.02 avg=0.04\n",
            "[444 | 238.16] loss=0.01 avg=0.03\n",
            "[445 | 238.60] loss=0.01 avg=0.03\n",
            "[446 | 239.04] loss=0.01 avg=0.03\n",
            "[447 | 239.49] loss=0.02 avg=0.03\n",
            "[448 | 239.93] loss=0.05 avg=0.03\n",
            "[449 | 240.37] loss=0.09 avg=0.03\n",
            "[450 | 240.81] loss=0.01 avg=0.03\n",
            "[451 | 241.25] loss=0.03 avg=0.03\n",
            "[452 | 241.69] loss=0.01 avg=0.03\n",
            "[453 | 242.13] loss=0.01 avg=0.03\n",
            "[454 | 242.58] loss=0.01 avg=0.03\n",
            "[455 | 243.01] loss=0.04 avg=0.03\n",
            "[456 | 243.46] loss=0.05 avg=0.03\n",
            "[457 | 243.90] loss=0.02 avg=0.03\n",
            "[458 | 244.34] loss=0.02 avg=0.03\n",
            "[459 | 244.78] loss=0.01 avg=0.03\n",
            "[460 | 245.22] loss=0.02 avg=0.03\n",
            "[461 | 245.66] loss=0.02 avg=0.03\n",
            "[462 | 246.11] loss=0.02 avg=0.03\n",
            "[463 | 246.55] loss=0.01 avg=0.03\n",
            "[464 | 246.99] loss=0.03 avg=0.03\n",
            "[465 | 247.43] loss=0.03 avg=0.03\n",
            "[466 | 247.87] loss=0.01 avg=0.03\n",
            "[467 | 248.31] loss=0.02 avg=0.03\n",
            "[468 | 248.75] loss=0.02 avg=0.03\n",
            "[469 | 249.20] loss=0.02 avg=0.03\n",
            "[470 | 249.64] loss=0.02 avg=0.03\n",
            "[471 | 250.08] loss=0.01 avg=0.03\n",
            "[472 | 250.52] loss=0.01 avg=0.03\n",
            "[473 | 250.97] loss=0.01 avg=0.03\n",
            "[474 | 251.41] loss=0.01 avg=0.03\n",
            "[475 | 251.85] loss=0.01 avg=0.03\n",
            "[476 | 252.29] loss=0.01 avg=0.03\n",
            "[477 | 252.74] loss=0.06 avg=0.03\n",
            "[478 | 253.18] loss=0.01 avg=0.03\n",
            "[479 | 253.62] loss=0.02 avg=0.03\n",
            "[480 | 254.06] loss=0.01 avg=0.03\n",
            "[481 | 254.50] loss=0.01 avg=0.03\n",
            "[482 | 254.95] loss=0.02 avg=0.03\n",
            "[483 | 255.39] loss=0.02 avg=0.03\n",
            "[484 | 255.83] loss=0.01 avg=0.03\n",
            "[485 | 256.27] loss=0.01 avg=0.03\n",
            "[486 | 256.72] loss=0.02 avg=0.03\n",
            "[487 | 257.16] loss=0.01 avg=0.03\n",
            "[488 | 257.60] loss=0.02 avg=0.03\n",
            "[489 | 258.04] loss=0.01 avg=0.03\n",
            "[490 | 258.49] loss=0.02 avg=0.03\n",
            "[491 | 258.93] loss=0.02 avg=0.03\n",
            "[492 | 259.37] loss=0.01 avg=0.03\n",
            "[493 | 259.81] loss=0.02 avg=0.03\n",
            "[494 | 260.25] loss=0.02 avg=0.03\n",
            "[495 | 260.69] loss=0.01 avg=0.03\n",
            "[496 | 261.13] loss=0.03 avg=0.03\n",
            "[497 | 261.58] loss=0.01 avg=0.03\n",
            "[498 | 262.02] loss=0.02 avg=0.03\n",
            "[499 | 262.46] loss=0.02 avg=0.03\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " no one was telling the truth or engaging the common man's point of view.\n",
            "\n",
            "The play was well interpreted by all whom were involved. Steven Wrentmore, the Director, kept the 1920’s feel by dressing in all 1920’s costumes and everyone spoke as if they were living at the time. Michelle Bisbee, the scene designer, made the inside of the home appear 1920’s because everything was grand. The Bliss’ home was grand with the spiral staircase, the very large backdoors, and the eloquent piano. The actors’ mannerisms seemed like they were portraying a silent film. In older movies, actors seemed very dramatic and had flamboyant actions to prove so; the actors in Hay Fever shared the same feel for the dramatics. As far as Stephen Wrentmore’s directing goes, he did an excellent job. The scene when Chris Karl (Richard) and Caitlin Stegemoller (Jackie) enter and are left alone to make small talk with each other is the best pertaining to directing. The two actors used the entire stage in this scene and were very awkward with one another. This was Wrentmore’s doing because you could tell he had a vision for this scene in particular because it seemed very crisp and well rehearsed. The actors played it perfect with the excessively long pauses in their awkward small talk that the crowd was laughing through the entire scene. It appeared that Wrentmore instructed the actors, to keep their pauses longer than natural to heighten the awkward tension in the scene, which made it brilliant.\n",
            "\n",
            "The blocking throughout the play worked with the floor plan very well. All of the blocking worked seamlessly; the actors were never out of sight or in awkward positioning (ex. turned around, talking to someone behind them while face forward, etc.) even during the second act in the first scene while all eight actors were on set. One part of the set that stood out was the staircase, it is obviously very large, but the way Owen Virgin followed Megan Davis up the stairs was seamless. They both walked up the stairs with footsteps I unison, and Owen Virgin was so focused on every detail of Davis, it almost screamed out how much he was infatuated with her.\n",
            "\n",
            "The artistic intent of this production was to entertain, and it fulfilled that intent completely. The entire audience was laughing during most of the production, I was even laughing out loud, which doesn’t happen very often. Every interaction between the characters was comical at one point during the production. An example of this playing out would be in the second act when Rascher busts through the door and proclaims his engagement. The only purpose of this is to entertain and entertain it did. The actors were able to slip by everyone that was laughing during the first act while everyone else was down to the last word.\n",
            "\n",
            "The overall mood that was portrayed by the combination of lighting, sound, set, and costumes was very light and cheerful; at no point did the mood drop to something darker or saddening. This is common with many comedies because it becomes hard to laugh if the overall mood is down and dreary. The theatre space was very personal. First of all, it takes place in someone’s home so it is immediately personal. Also, the stage was built into the crowd just about so the audience felt like they were living the action out as it unfolded. The scenic design showed the audience without a doubt it was the 1920’s, with the barometer on the wall, the staircase, the piano, and the lights upstairs. However, there was little evidence to show what location the play took place.\n",
            "\n",
            "All of the costumes were well designed for the appropriate characters. Adam Espinoza did a fine job of showing how these people were all high class and social outcasts who often flaunted their status as such through their costumes. My only complaint is that the price of a set was introduced in the most economical setting I have seen. The usual costs about $100 or more. The added value of cheaper seats took up less space in the house than cheaper and resulted in a more cost-effective experience for the average homeen.\n",
            "\n",
            "This production was definitely representational because it doesn’t fall for the common man’s illusion of the show being about money, the very few dollars earned by the average citizen. The same is true of the costumes used in the first act. The only difference being that costumes were more expensive and therefore more commonly used. The actors used cheaper materials and made costumes more expensive.\n",
            "\n",
            "The overall message seemed to be: do not mislead people or use people for personal gain. This is a PG-13 audience and it was sent as such.\n",
            "\n",
            "For more information, please visit the official Ozars website or call the Georgia Theater’s toll-free’s-at-866-467-2555.\n",
            "\n",
            "‪\n",
            "\n",
            "** All ratings are intended to be an\n",
            "\n",
            "[500 | 273.57] loss=0.01 avg=0.03\n",
            "[501 | 274.01] loss=0.01 avg=0.03\n",
            "[502 | 274.46] loss=0.01 avg=0.03\n",
            "[503 | 274.90] loss=0.02 avg=0.03\n",
            "[504 | 275.34] loss=0.01 avg=0.03\n",
            "[505 | 275.79] loss=0.01 avg=0.03\n",
            "[506 | 276.23] loss=0.02 avg=0.03\n",
            "[507 | 276.67] loss=0.02 avg=0.03\n",
            "[508 | 277.11] loss=0.01 avg=0.03\n",
            "[509 | 277.55] loss=0.01 avg=0.03\n",
            "[510 | 278.00] loss=0.02 avg=0.03\n",
            "[511 | 278.44] loss=0.01 avg=0.03\n",
            "[512 | 278.88] loss=0.01 avg=0.03\n",
            "[513 | 279.33] loss=0.01 avg=0.03\n",
            "[514 | 279.77] loss=0.01 avg=0.03\n",
            "[515 | 280.21] loss=0.01 avg=0.03\n",
            "[516 | 280.65] loss=0.01 avg=0.03\n",
            "[517 | 281.10] loss=0.01 avg=0.03\n",
            "[518 | 281.54] loss=0.01 avg=0.03\n",
            "[519 | 281.98] loss=0.02 avg=0.03\n",
            "[520 | 282.43] loss=0.01 avg=0.02\n",
            "[521 | 282.87] loss=0.01 avg=0.02\n",
            "[522 | 283.31] loss=0.01 avg=0.02\n",
            "[523 | 283.75] loss=0.01 avg=0.02\n",
            "[524 | 284.20] loss=0.01 avg=0.02\n",
            "[525 | 284.64] loss=0.03 avg=0.02\n",
            "[526 | 285.08] loss=0.01 avg=0.02\n",
            "[527 | 285.53] loss=0.01 avg=0.02\n",
            "[528 | 285.97] loss=0.01 avg=0.02\n",
            "[529 | 286.41] loss=0.03 avg=0.02\n",
            "[530 | 286.86] loss=0.01 avg=0.02\n",
            "[531 | 287.30] loss=0.01 avg=0.02\n",
            "[532 | 287.74] loss=0.01 avg=0.02\n",
            "[533 | 288.18] loss=0.01 avg=0.02\n",
            "[534 | 288.63] loss=0.01 avg=0.02\n",
            "[535 | 289.07] loss=0.01 avg=0.02\n",
            "[536 | 289.52] loss=0.03 avg=0.02\n",
            "[537 | 289.96] loss=0.03 avg=0.02\n",
            "[538 | 290.40] loss=0.03 avg=0.02\n",
            "[539 | 290.84] loss=0.02 avg=0.02\n",
            "[540 | 291.29] loss=0.01 avg=0.02\n",
            "[541 | 291.73] loss=0.01 avg=0.02\n",
            "[542 | 292.17] loss=0.01 avg=0.02\n",
            "[543 | 292.61] loss=0.01 avg=0.02\n",
            "[544 | 293.06] loss=0.01 avg=0.02\n",
            "[545 | 293.50] loss=0.01 avg=0.02\n",
            "[546 | 293.95] loss=0.06 avg=0.02\n",
            "[547 | 294.39] loss=0.01 avg=0.02\n",
            "[548 | 294.83] loss=0.02 avg=0.02\n",
            "[549 | 295.27] loss=0.01 avg=0.02\n",
            "[550 | 295.71] loss=0.02 avg=0.02\n",
            "[551 | 296.16] loss=0.01 avg=0.02\n",
            "[552 | 296.60] loss=0.01 avg=0.02\n",
            "[553 | 297.05] loss=0.02 avg=0.02\n",
            "[554 | 297.49] loss=0.02 avg=0.02\n",
            "[555 | 297.93] loss=0.01 avg=0.02\n",
            "[556 | 298.37] loss=0.01 avg=0.02\n",
            "[557 | 298.82] loss=0.01 avg=0.02\n",
            "[558 | 299.26] loss=0.02 avg=0.02\n",
            "[559 | 299.70] loss=0.01 avg=0.02\n",
            "[560 | 300.15] loss=0.01 avg=0.02\n",
            "[561 | 300.59] loss=0.01 avg=0.02\n",
            "[562 | 301.03] loss=0.02 avg=0.02\n",
            "[563 | 301.48] loss=0.03 avg=0.02\n",
            "[564 | 301.92] loss=0.01 avg=0.02\n",
            "[565 | 302.36] loss=0.01 avg=0.02\n",
            "[566 | 302.80] loss=0.01 avg=0.02\n",
            "[567 | 303.25] loss=0.00 avg=0.02\n",
            "[568 | 303.69] loss=0.02 avg=0.02\n",
            "[569 | 304.13] loss=0.01 avg=0.02\n",
            "[570 | 304.57] loss=0.01 avg=0.02\n",
            "[571 | 305.02] loss=0.01 avg=0.02\n",
            "[572 | 305.46] loss=0.04 avg=0.02\n",
            "[573 | 305.91] loss=0.01 avg=0.02\n",
            "[574 | 306.35] loss=0.01 avg=0.02\n",
            "[575 | 306.79] loss=0.02 avg=0.02\n",
            "[576 | 307.23] loss=0.01 avg=0.02\n",
            "[577 | 307.68] loss=0.02 avg=0.02\n",
            "[578 | 308.12] loss=0.01 avg=0.02\n",
            "[579 | 308.57] loss=0.02 avg=0.02\n",
            "[580 | 309.01] loss=0.01 avg=0.02\n",
            "[581 | 309.45] loss=0.01 avg=0.02\n",
            "[582 | 309.89] loss=0.02 avg=0.02\n",
            "[583 | 310.34] loss=0.01 avg=0.02\n",
            "[584 | 310.78] loss=0.01 avg=0.02\n",
            "[585 | 311.22] loss=0.01 avg=0.02\n",
            "[586 | 311.66] loss=0.01 avg=0.02\n",
            "[587 | 312.11] loss=0.03 avg=0.02\n",
            "[588 | 312.55] loss=0.01 avg=0.02\n",
            "[589 | 312.99] loss=0.01 avg=0.02\n",
            "[590 | 313.44] loss=0.01 avg=0.02\n",
            "[591 | 313.89] loss=0.01 avg=0.02\n",
            "[592 | 314.33] loss=0.01 avg=0.02\n",
            "[593 | 314.77] loss=0.02 avg=0.02\n",
            "[594 | 315.22] loss=0.01 avg=0.02\n",
            "[595 | 315.66] loss=0.03 avg=0.02\n",
            "[596 | 316.10] loss=0.01 avg=0.02\n",
            "[597 | 316.55] loss=0.01 avg=0.02\n",
            "[598 | 316.99] loss=0.01 avg=0.02\n",
            "[599 | 317.43] loss=0.01 avg=0.02\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " house of worship. In the day, the People were portrayed as local, with the main floor set up for over a week's worth of activity throughout the year. Each house featured a play or two in particular that appealed to the typical family. For example, the Two Strings at the center of the house appeared to be romantic comedies; they were all in good fun with a large group. Each family member acted dramatic; there were no spectators and no drama. One person spoke asif he or she was talking and the other as if acting. There was one person who spoke as if he or she was talking and the other as if pretending to be. There was no point at which you had to be certain that what you were saying was right. For example, if a man in a bar was saying the word \"bimbo,\" I would be certain he was speaking as if he were talking. The only requirement was that he or she was physically imposing. This was a changing of the guard situation. If a man was physically imposing and took the stage, I would assume he was doing so out of politeness for a young male student with a large family. However, if he or she was making a point of showing affection for a character, such as by saying, \"Hi,\" I would be certain he was talking about him.\n",
            "\n",
            "The play was well interpreted by all whom were involved. Steven Wrentmore, the Director, kept the 1920’s feel by dressing in all 1920’s costumes and everyone spoke as if they were living at the time. Michelle Bisbee, the scene designer, made the inside of the home appear 1920’s because everything was grand. The Bliss’ home was grand with the spiral staircase, the very large backdoors, and the eloquent piano. The actors’ mannerisms seemed like they were portraying a silent film. In older movies, actors seemed very dramatic and had flamboyant actions to prove so; the actors in Hay Fever shared the same feel for the dramatics. As far as Stephen Wrentmore’s directing goes, he did an excellent job. The scene when Chris Karl (Richard) and Caitlin Stegemoller (Jackie) enter and are left alone to make small talk with each other is the best pertaining to directing. The two actors used the entire stage in this scene and were very awkward with one another. This was Wrentmore’s doing because you could tell he had a vision for this scene in particular because it seemed very crisp and well rehearsed. The actors played it perfect with the excessively long pauses in their awkward small talk that the crowd was laughing through the entire scene. It appeared that Wrentmore instructed the actors, to keep their pauses longer than natural to heighten the awkward tension in the scene, which made it brilliant.\n",
            "\n",
            "The blocking throughout the play worked with the floor plan very well. All of the blocking worked seamlessly; the actors were never out of sight or in awkward positioning (ex. turned around, talking to someone behind them while face forward, etc.) even during the second act in the first scene while all eight actors were on set. One part of the set that stood out was the staircase, it is obviously very large, but the way Owen Virgin followed Megan Davis up the stairs was seamless. They both walked up the stairs with footsteps I unison, and Owen Virgin was so focused on every detail of Davis, it almost screamed out how much he was infatuated with her.\n",
            "\n",
            "The artistic intent of this production was to entertain, and it fulfilled that intent completely. The entire audience was laughing during most of the production, I was even laughing out loud, which doesn’t happen very often. Every interaction between the characters was comical at one point during the production. An example of this playing out would be in the second act when Rascher Scarely stole all of Megan Davis’s family’ home and used it as a stage. Richard was causing a scene by stealing the attention, whereas Rascher Simply was using the space as his own and did as much as anyone was taking him. Each and every interaction between the characters was comical. An example of this playing out would be in the second act when Rascher Scarely stole all of Davis’s family’ home and used it as a stage. Richard was causing a scene by stealing the attention, whereas Rascher Simply was using the space as his own and did as much as anyone is taking him.\n",
            "\n",
            "The overall mood that was portrayed by the combination of lighting, sound, set, and costumes was very light and cheerful; at no point did the mood drop to something darker or saddening. This is common with many comedies because it becomes hard to laugh if the overall mood is down and dreary. The theatre space was very personal. First of all, it takes place in someone’s home so it is immediately personal. Also, the stage was built into the crowd just about so the\n",
            "\n",
            "[600 | 327.96] loss=0.01 avg=0.02\n",
            "[601 | 328.40] loss=0.01 avg=0.02\n",
            "[602 | 328.84] loss=0.05 avg=0.02\n",
            "[603 | 329.29] loss=0.01 avg=0.02\n",
            "[604 | 329.73] loss=0.04 avg=0.02\n",
            "[605 | 330.18] loss=0.01 avg=0.02\n",
            "[606 | 330.62] loss=0.01 avg=0.02\n",
            "[607 | 331.06] loss=0.02 avg=0.02\n",
            "[608 | 331.51] loss=0.01 avg=0.02\n",
            "[609 | 331.95] loss=0.01 avg=0.02\n",
            "[610 | 332.40] loss=0.02 avg=0.02\n",
            "[611 | 332.84] loss=0.01 avg=0.02\n",
            "[612 | 333.28] loss=0.01 avg=0.02\n",
            "[613 | 333.73] loss=0.02 avg=0.02\n",
            "[614 | 334.17] loss=0.01 avg=0.02\n",
            "[615 | 334.62] loss=0.02 avg=0.02\n",
            "[616 | 335.06] loss=0.02 avg=0.02\n",
            "[617 | 335.51] loss=0.01 avg=0.02\n",
            "[618 | 335.95] loss=0.01 avg=0.02\n",
            "[619 | 336.39] loss=0.02 avg=0.02\n",
            "[620 | 336.83] loss=0.01 avg=0.02\n",
            "[621 | 337.28] loss=0.01 avg=0.02\n",
            "[622 | 337.72] loss=0.01 avg=0.02\n",
            "[623 | 338.17] loss=0.02 avg=0.02\n",
            "[624 | 338.61] loss=0.01 avg=0.02\n",
            "[625 | 339.06] loss=0.01 avg=0.02\n",
            "[626 | 339.51] loss=0.01 avg=0.02\n",
            "[627 | 339.95] loss=0.01 avg=0.02\n",
            "[628 | 340.39] loss=0.01 avg=0.02\n",
            "[629 | 340.83] loss=0.02 avg=0.02\n",
            "[630 | 341.28] loss=0.01 avg=0.02\n",
            "[631 | 341.72] loss=0.00 avg=0.02\n",
            "[632 | 342.17] loss=0.01 avg=0.02\n",
            "[633 | 342.61] loss=0.01 avg=0.02\n",
            "[634 | 343.06] loss=0.01 avg=0.02\n",
            "[635 | 343.50] loss=0.01 avg=0.02\n",
            "[636 | 343.95] loss=0.01 avg=0.02\n",
            "[637 | 344.39] loss=0.01 avg=0.02\n",
            "[638 | 344.83] loss=0.01 avg=0.02\n",
            "[639 | 345.28] loss=0.01 avg=0.02\n",
            "[640 | 345.72] loss=0.02 avg=0.02\n",
            "[641 | 346.17] loss=0.01 avg=0.02\n",
            "[642 | 346.61] loss=0.01 avg=0.02\n",
            "[643 | 347.06] loss=0.01 avg=0.02\n",
            "[644 | 347.50] loss=0.02 avg=0.02\n",
            "[645 | 347.95] loss=0.00 avg=0.02\n",
            "[646 | 348.39] loss=0.01 avg=0.02\n",
            "[647 | 348.83] loss=0.01 avg=0.02\n",
            "[648 | 349.28] loss=0.01 avg=0.02\n",
            "[649 | 349.72] loss=0.01 avg=0.02\n",
            "[650 | 350.17] loss=0.01 avg=0.02\n",
            "[651 | 350.61] loss=0.01 avg=0.02\n",
            "[652 | 351.06] loss=0.01 avg=0.02\n",
            "[653 | 351.51] loss=0.02 avg=0.02\n",
            "[654 | 351.95] loss=0.01 avg=0.02\n",
            "[655 | 352.40] loss=0.01 avg=0.02\n",
            "[656 | 352.85] loss=0.01 avg=0.02\n",
            "[657 | 353.29] loss=0.01 avg=0.02\n",
            "[658 | 353.74] loss=0.01 avg=0.02\n",
            "[659 | 354.19] loss=0.02 avg=0.02\n",
            "[660 | 354.63] loss=0.01 avg=0.02\n",
            "[661 | 355.08] loss=0.02 avg=0.02\n",
            "[662 | 355.52] loss=0.01 avg=0.02\n",
            "[663 | 355.96] loss=0.01 avg=0.02\n",
            "[664 | 356.41] loss=0.01 avg=0.02\n",
            "[665 | 356.85] loss=0.01 avg=0.02\n",
            "[666 | 357.30] loss=0.01 avg=0.02\n",
            "[667 | 357.74] loss=0.01 avg=0.02\n",
            "[668 | 358.19] loss=0.01 avg=0.02\n",
            "[669 | 358.63] loss=0.01 avg=0.02\n",
            "[670 | 359.08] loss=0.01 avg=0.02\n",
            "[671 | 359.53] loss=0.01 avg=0.02\n",
            "[672 | 359.97] loss=0.03 avg=0.02\n",
            "[673 | 360.42] loss=0.01 avg=0.02\n",
            "[674 | 360.87] loss=0.01 avg=0.02\n",
            "[675 | 361.31] loss=0.02 avg=0.02\n",
            "[676 | 361.76] loss=0.01 avg=0.02\n",
            "[677 | 362.21] loss=0.01 avg=0.02\n",
            "[678 | 362.65] loss=0.01 avg=0.02\n",
            "[679 | 363.10] loss=0.00 avg=0.02\n",
            "[680 | 363.54] loss=0.03 avg=0.02\n",
            "[681 | 363.99] loss=0.01 avg=0.02\n",
            "[682 | 364.43] loss=0.01 avg=0.02\n",
            "[683 | 364.88] loss=0.01 avg=0.02\n",
            "[684 | 365.32] loss=0.02 avg=0.02\n",
            "[685 | 365.77] loss=0.01 avg=0.02\n",
            "[686 | 366.21] loss=0.01 avg=0.02\n",
            "[687 | 366.66] loss=0.01 avg=0.02\n",
            "[688 | 367.10] loss=0.01 avg=0.02\n",
            "[689 | 367.55] loss=0.01 avg=0.02\n",
            "[690 | 367.99] loss=0.02 avg=0.02\n",
            "[691 | 368.44] loss=0.01 avg=0.02\n",
            "[692 | 368.88] loss=0.01 avg=0.01\n",
            "[693 | 369.32] loss=0.01 avg=0.01\n",
            "[694 | 369.77] loss=0.00 avg=0.01\n",
            "[695 | 370.21] loss=0.01 avg=0.01\n",
            "[696 | 370.66] loss=0.01 avg=0.01\n",
            "[697 | 371.11] loss=0.01 avg=0.01\n",
            "[698 | 371.56] loss=0.01 avg=0.01\n",
            "[699 | 372.00] loss=0.01 avg=0.01\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            "en and Amy Acker.\n",
            "\n",
            "The play was well interpreted by all whom were involved. Steven Wrentmore, the Director, kept the 1920’s feel by dressing in all 1920’s costumes and everyone spoke as if they were living at the time. Michelle Bisbee, the scene designer, made the inside of the home appear 1920’s because everything was grand. The Bliss’ home was grand with the spiral staircase, the very large backdoors, and the eloquent piano. The actors’ mannerisms seemed like they were portraying a silent film. In older movies, actors seemed very dramatic and had flamboyant actions to prove so; the actors in Hay Fever shared the same feel for the dramatics. As far as Stephen Wrentmore’s directing goes, he did an excellent job. The scene when Chris Karl (Richard) and Caitlin Stegemoller (Jackie) enter and are left alone to make small talk with each other is the best pertaining to directing. The two actors used the entire stage in this scene and were very awkward with one another. This was Wrentmore’s doing because you could tell he had a vision for this scene in particular because it seemed very crisp and well rehearsed. The actors played it perfect with the excessively long pauses in their awkward small talk that the crowd was laughing through the entire scene. It appeared that Wrentmore instructed the actors, to keep their pauses longer than natural to heighten the awkward tension in the scene, which made it brilliant.\n",
            "\n",
            "The blocking throughout the play worked with the floor plan very well. All of the blocking worked seamlessly; the actors were never out of sight or in awkward positioning (ex. turned around, talking to someone behind them while face forward, etc.) even during the second act in the first scene while all eight actors were on set. One part of the set that stood out was the staircase, it is obviously very large, but the way Owen Virgin followed Megan Davis up the stairs was seamless. They both walked up the stairs with footsteps I unison, and Owen Virgin was so focused on every detail of Davis, it almost screamed out how much he was infatuated with her.\n",
            "\n",
            "The artistic intent of this production was to entertain, and it fulfilled that intent completely. The entire audience was laughing during most of the production, I was even laughing out loud, which doesn’t happen very often. Every interaction between the characters was comical at one point during the production. An example of this playing out would be in the second act when Rascher busts through the door and proclaims his engagement. The only purpose of this is to entertain and entertain it did. The actors seemed natural moving along with their blocking and engaging with each other on stage. There was no point at which it was confusing why someone moved here or there, every movement made sense.\n",
            "\n",
            "The overall mood that was portrayed by the combination of lighting, sound, set, and costumes was very light and cheerful; at no point did the mood drop to something darker or saddening. This is common with many comedies because it becomes hard to laugh if the overall mood is down and dreary. The theatre space was very personal. First of all, it takes place in someone’s home so it is immediately personal. Also, the stage was built into the crowd just about so the audience felt like they were living the action out as it unfolded. The scenic design showed the audience without a doubt it was the 1920’s, with the barometer on the wall, the staircase, the piano, and the lights upstairs. However, there was little evidence to show what location the play took place.\n",
            "\n",
            "All of the costumes were well designed for the appropriate characters. Adam Espinoza did a fine job of showing how these people were all upper class with nice dresses and suits and tuxes, even when they were home alone with only each other as company. Megan Davis’ costumes represented her personality very well by drawing all attention to her with bright colors and silk-like texture. As far as the lighting goes, there were no changes to the lighting during the play, except for at the end of each act. The lighting emphasized a bright and cheerful mood throughout the play.\n",
            "\n",
            "This production was definitely representational because it doesn’t break the fourth wall into the audience. The actors never had any asides or soliloquies that were directed toward audience. The set and lighting were representational due to the realistic feel throughout the house, everything was relatable to the average person. The Bliss’ home looked like an ordinary home from the 1920’s.\n",
            "\n",
            "The overall message seemed to be: do not mislead people or play games with their emotions, or they will leave you. This was most clear during act three when Luz, Karl, Stegemoller, and Virgin were all discussing how uncomfortable they all had felt the day before in the house and decided to leave as soon as\n",
            "\n",
            "[700 | 382.60] loss=0.01 avg=0.01\n",
            "[701 | 383.05] loss=0.01 avg=0.01\n",
            "[702 | 383.49] loss=0.01 avg=0.01\n",
            "[703 | 383.94] loss=0.01 avg=0.01\n",
            "[704 | 384.38] loss=0.01 avg=0.01\n",
            "[705 | 384.83] loss=0.01 avg=0.01\n",
            "[706 | 385.28] loss=0.01 avg=0.01\n",
            "[707 | 385.73] loss=0.00 avg=0.01\n",
            "[708 | 386.17] loss=0.01 avg=0.01\n",
            "[709 | 386.62] loss=0.01 avg=0.01\n",
            "[710 | 387.06] loss=0.01 avg=0.01\n",
            "[711 | 387.51] loss=0.01 avg=0.01\n",
            "[712 | 387.95] loss=0.01 avg=0.01\n",
            "[713 | 388.39] loss=0.01 avg=0.01\n",
            "[714 | 388.84] loss=0.01 avg=0.01\n",
            "[715 | 389.28] loss=0.02 avg=0.01\n",
            "[716 | 389.73] loss=0.01 avg=0.01\n",
            "[717 | 390.18] loss=0.01 avg=0.01\n",
            "[718 | 390.62] loss=0.01 avg=0.01\n",
            "[719 | 391.07] loss=0.00 avg=0.01\n",
            "[720 | 391.52] loss=0.05 avg=0.01\n",
            "[721 | 391.97] loss=0.01 avg=0.01\n",
            "[722 | 392.41] loss=0.01 avg=0.01\n",
            "[723 | 392.86] loss=0.01 avg=0.01\n",
            "[724 | 393.30] loss=0.02 avg=0.01\n",
            "[725 | 393.75] loss=0.01 avg=0.01\n",
            "[726 | 394.19] loss=0.01 avg=0.01\n",
            "[727 | 394.64] loss=0.01 avg=0.01\n",
            "[728 | 395.08] loss=0.01 avg=0.01\n",
            "[729 | 395.53] loss=0.01 avg=0.01\n",
            "[730 | 395.98] loss=0.02 avg=0.01\n",
            "[731 | 396.42] loss=0.01 avg=0.01\n",
            "[732 | 396.87] loss=0.02 avg=0.01\n",
            "[733 | 397.32] loss=0.01 avg=0.01\n",
            "[734 | 397.76] loss=0.01 avg=0.01\n",
            "[735 | 398.21] loss=0.01 avg=0.01\n",
            "[736 | 398.66] loss=0.01 avg=0.01\n",
            "[737 | 399.11] loss=0.02 avg=0.01\n",
            "[738 | 399.55] loss=0.01 avg=0.01\n",
            "[739 | 400.00] loss=0.01 avg=0.01\n",
            "[740 | 400.45] loss=0.02 avg=0.01\n",
            "[741 | 400.89] loss=0.01 avg=0.01\n",
            "[742 | 401.34] loss=0.01 avg=0.01\n",
            "[743 | 401.79] loss=0.00 avg=0.01\n",
            "[744 | 402.23] loss=0.02 avg=0.01\n",
            "[745 | 402.68] loss=0.01 avg=0.01\n",
            "[746 | 403.12] loss=0.01 avg=0.01\n",
            "[747 | 403.57] loss=0.01 avg=0.01\n",
            "[748 | 404.01] loss=0.01 avg=0.01\n",
            "[749 | 404.46] loss=0.01 avg=0.01\n",
            "[750 | 404.90] loss=0.01 avg=0.01\n",
            "[751 | 405.34] loss=0.01 avg=0.01\n",
            "[752 | 405.79] loss=0.01 avg=0.01\n",
            "[753 | 406.24] loss=0.02 avg=0.01\n",
            "[754 | 406.68] loss=0.01 avg=0.01\n",
            "[755 | 407.13] loss=0.01 avg=0.01\n",
            "[756 | 407.58] loss=0.01 avg=0.01\n",
            "[757 | 408.02] loss=0.01 avg=0.01\n",
            "[758 | 408.47] loss=0.01 avg=0.01\n",
            "[759 | 408.92] loss=0.01 avg=0.01\n",
            "[760 | 409.36] loss=0.01 avg=0.01\n",
            "[761 | 409.81] loss=0.01 avg=0.01\n",
            "[762 | 410.26] loss=0.01 avg=0.01\n",
            "[763 | 410.70] loss=0.01 avg=0.01\n",
            "[764 | 411.15] loss=0.01 avg=0.01\n",
            "[765 | 411.59] loss=0.01 avg=0.01\n",
            "[766 | 412.04] loss=0.03 avg=0.01\n",
            "[767 | 412.49] loss=0.02 avg=0.01\n",
            "[768 | 412.93] loss=0.02 avg=0.01\n",
            "[769 | 413.38] loss=0.02 avg=0.01\n",
            "[770 | 413.83] loss=0.01 avg=0.01\n",
            "[771 | 414.27] loss=0.01 avg=0.01\n",
            "[772 | 414.72] loss=0.00 avg=0.01\n",
            "[773 | 415.17] loss=0.01 avg=0.01\n",
            "[774 | 415.61] loss=0.01 avg=0.01\n",
            "[775 | 416.06] loss=0.01 avg=0.01\n",
            "[776 | 416.51] loss=0.02 avg=0.01\n",
            "[777 | 416.95] loss=0.01 avg=0.01\n",
            "[778 | 417.40] loss=0.01 avg=0.01\n",
            "[779 | 417.85] loss=0.01 avg=0.01\n",
            "[780 | 418.29] loss=0.00 avg=0.01\n",
            "[781 | 418.74] loss=0.01 avg=0.01\n",
            "[782 | 419.18] loss=0.01 avg=0.01\n",
            "[783 | 419.63] loss=0.01 avg=0.01\n",
            "[784 | 420.08] loss=0.01 avg=0.01\n",
            "[785 | 420.53] loss=0.01 avg=0.01\n",
            "[786 | 420.97] loss=0.02 avg=0.01\n",
            "[787 | 421.42] loss=0.01 avg=0.01\n",
            "[788 | 421.87] loss=0.01 avg=0.01\n",
            "[789 | 422.31] loss=0.01 avg=0.01\n",
            "[790 | 422.76] loss=0.01 avg=0.01\n",
            "[791 | 423.20] loss=0.01 avg=0.01\n",
            "[792 | 423.65] loss=0.01 avg=0.01\n",
            "[793 | 424.10] loss=0.01 avg=0.01\n",
            "[794 | 424.54] loss=0.01 avg=0.01\n",
            "[795 | 424.99] loss=0.01 avg=0.01\n",
            "[796 | 425.44] loss=0.01 avg=0.01\n",
            "[797 | 425.88] loss=0.00 avg=0.01\n",
            "[798 | 426.33] loss=0.01 avg=0.01\n",
            "[799 | 426.78] loss=0.02 avg=0.01\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " scene was real, the actual leaflets spread out over the ground was common for newspapers to appear alongside one another, and the stage was nearly completely covered in brightening lights throughout the day.\n",
            "\n",
            "The park was well lit for the duration of the play; the stage was nearly never fully lit during the first act due to the large backstage in first act three that was almost comical in nature. The stage took place inside the Bliss’ home so the bright lighting added a confortable feel to the inside of the house. The theatre was nearly sold out; it was hard to spot an empty seat, including the balcony and lower level seating. The crowd contained nearly an even amount of student audience members and senior citizens; there was few in the audience that appeared middle aged.\n",
            "\n",
            "The play was well cast, the entire Bliss family did a great job showing how overly dramatic and deceitful the family had become. Each actor portrayed their character accurately; there were no standouts that didn’t match the character. Each visitor in act four seemed to be feasible as far as the possibility of a relationship was concerned. All of the family members acted genuine. There was one actor who stood out as a perfect fit for his character. Taylor Rascher played Simon Bliss and played him perfectly. Rascher’s character Simon was a young man who was dramatic and romantic so much so it was almost to the point of ridiculousness. Rascher stole the show in the first act when he was romancing with Michelle Luz, who plays Myra Arundel. Rascher was displaying his love for Michelle Luz (Myra) in the most dramatic of fashions; he was playing the Bliss’ game of pretending to be in complete love with someone and then a moment later change his mind. Rascher was proclaiming his love with elegant speeches and coddling up next to her and eventually kissing her. Rascher made this scene particularly hilarious because he was completely over the top in typical Bliss fashion. Of course, all of this was for naught because Luz ended up kissing Joe Hubbard’s character David Bliss in act four and also Rascher proclaimed his engagement to Caitlin Stagemoller’s character, Jackie Coryton. Rascher made his voice more shrill and audible to appear to be more dramatic and create more attention for himself. In the same way, Rascher used grander gestures with his arms (flailing, waving, etc.) to cause a more dramatic effect.\n",
            "\n",
            "The play was well interpreted by all whom were involved. Steven Wrentmore, the Director, kept the 1920’s feel by dressing in all 1920’s costumes and everyone spoke as if they were living at the time. Michelle Bisbee, the scene designer, made the inside of the home appear 1920’s because everything was grand. The Bliss’ home was grand with the spiral staircase, the very large backdoors, and the eloquent piano. The actors’ mannerisms seemed like they were portraying a silent film. In older movies, actors seemed very dramatic and had flamboyant actions to prove so; the actors in Hay Fever shared the same feel for the dramatics. As far as Stephen Wrentmore’s directing goes, he did an excellent job. The scene when Chris Karl (Richard) and Caitlin Stegemoller (Jackie) enter and are left alone to make small talk with each other is the best pertaining to directing. The two actors used the entire stage in this scene and were very awkward with one another. This was Wrentmore’s doing because you could tell he had a vision for this scene in particular because it seemed very crisp and well rehearsed. The actors played it perfect with the excessively long pauses in their awkward small talk that the crowd was laughing through the entire scene. It appeared that Wrentmore instructed the actors, to keep their pauses longer than natural to heighten the awkward tension in the scene, which made it brilliant.\n",
            "\n",
            "The blocking throughout the play worked with the floor floor plan very well. All of the blocking worked seamlessly; the actors were never out of sight or in awkward positioning (ex. turned around, talking to someone behind them while face forward, etc.) even during the second act in the first scene while all eight actors were on set. One part of the set that stood out was the staircase, it is obviously very large, but the way Owen Virgin followed Megan Davis up the stairs was seamless. They both walked up the stairs with footsteps I unison, and Owen Virgin was so focused on every detail of Davis, it almost screamed out how much he was infatuated with her.\n",
            "\n",
            "The artistic intent of this production was to entertain, and it fulfilled that intent completely. The entire audience was laughing during most of the production, I was even laughing out loud, which doesn’t happen very often. Every interaction between the characters was comical at one point during the production. An example of this playing out would be\n",
            "\n",
            "[800 | 437.65] loss=0.01 avg=0.01\n",
            "[801 | 438.10] loss=0.00 avg=0.01\n",
            "[802 | 438.55] loss=0.01 avg=0.01\n",
            "[803 | 438.99] loss=0.03 avg=0.01\n",
            "[804 | 439.44] loss=0.01 avg=0.01\n",
            "[805 | 439.88] loss=0.00 avg=0.01\n",
            "[806 | 440.33] loss=0.01 avg=0.01\n",
            "[807 | 440.78] loss=0.01 avg=0.01\n",
            "[808 | 441.22] loss=0.01 avg=0.01\n",
            "[809 | 441.67] loss=0.01 avg=0.01\n",
            "[810 | 442.12] loss=0.01 avg=0.01\n",
            "[811 | 442.57] loss=0.00 avg=0.01\n",
            "[812 | 443.01] loss=0.01 avg=0.01\n",
            "[813 | 443.46] loss=0.01 avg=0.01\n",
            "[814 | 443.91] loss=0.01 avg=0.01\n",
            "[815 | 444.35] loss=0.01 avg=0.01\n",
            "[816 | 444.80] loss=0.01 avg=0.01\n",
            "[817 | 445.25] loss=0.01 avg=0.01\n",
            "[818 | 445.70] loss=0.01 avg=0.01\n",
            "[819 | 446.14] loss=0.03 avg=0.01\n",
            "[820 | 446.59] loss=0.01 avg=0.01\n",
            "[821 | 447.04] loss=0.01 avg=0.01\n",
            "[822 | 447.49] loss=0.02 avg=0.01\n",
            "[823 | 447.93] loss=0.01 avg=0.01\n",
            "[824 | 448.38] loss=0.01 avg=0.01\n",
            "[825 | 448.83] loss=0.01 avg=0.01\n",
            "[826 | 449.27] loss=0.01 avg=0.01\n",
            "[827 | 449.72] loss=0.00 avg=0.01\n",
            "[828 | 450.17] loss=0.02 avg=0.01\n",
            "[829 | 450.61] loss=0.01 avg=0.01\n",
            "[830 | 451.06] loss=0.01 avg=0.01\n",
            "[831 | 451.50] loss=0.02 avg=0.01\n",
            "[832 | 451.95] loss=0.01 avg=0.01\n",
            "[833 | 452.40] loss=0.01 avg=0.01\n",
            "[834 | 452.84] loss=0.01 avg=0.01\n",
            "[835 | 453.29] loss=0.01 avg=0.01\n",
            "[836 | 453.74] loss=0.02 avg=0.01\n",
            "[837 | 454.18] loss=0.01 avg=0.01\n",
            "[838 | 454.63] loss=0.01 avg=0.01\n",
            "[839 | 455.08] loss=0.00 avg=0.01\n",
            "[840 | 455.53] loss=0.01 avg=0.01\n",
            "[841 | 455.97] loss=0.01 avg=0.01\n",
            "[842 | 456.42] loss=0.01 avg=0.01\n",
            "[843 | 456.87] loss=0.02 avg=0.01\n",
            "[844 | 457.31] loss=0.01 avg=0.01\n",
            "[845 | 457.76] loss=0.00 avg=0.01\n",
            "[846 | 458.21] loss=0.00 avg=0.01\n",
            "[847 | 458.66] loss=0.01 avg=0.01\n",
            "[848 | 459.10] loss=0.02 avg=0.01\n",
            "[849 | 459.55] loss=0.01 avg=0.01\n",
            "[850 | 460.00] loss=0.01 avg=0.01\n",
            "[851 | 460.44] loss=0.01 avg=0.01\n",
            "[852 | 460.89] loss=0.01 avg=0.01\n",
            "[853 | 461.34] loss=0.00 avg=0.01\n",
            "[854 | 461.78] loss=0.01 avg=0.01\n",
            "[855 | 462.23] loss=0.01 avg=0.01\n",
            "[856 | 462.68] loss=0.01 avg=0.01\n",
            "[857 | 463.12] loss=0.01 avg=0.01\n",
            "[858 | 463.57] loss=0.00 avg=0.01\n",
            "[859 | 464.02] loss=0.00 avg=0.01\n",
            "[860 | 464.46] loss=0.01 avg=0.01\n",
            "[861 | 464.91] loss=0.01 avg=0.01\n",
            "[862 | 465.36] loss=0.01 avg=0.01\n",
            "[863 | 465.81] loss=0.02 avg=0.01\n",
            "[864 | 466.25] loss=0.01 avg=0.01\n",
            "[865 | 466.70] loss=0.01 avg=0.01\n",
            "[866 | 467.15] loss=0.01 avg=0.01\n",
            "[867 | 467.60] loss=0.01 avg=0.01\n",
            "[868 | 468.04] loss=0.01 avg=0.01\n",
            "[869 | 468.49] loss=0.01 avg=0.01\n",
            "[870 | 468.94] loss=0.01 avg=0.01\n",
            "[871 | 469.39] loss=0.01 avg=0.01\n",
            "[872 | 469.84] loss=0.01 avg=0.01\n",
            "[873 | 470.28] loss=0.01 avg=0.01\n",
            "[874 | 470.73] loss=0.01 avg=0.01\n",
            "[875 | 471.17] loss=0.01 avg=0.01\n",
            "[876 | 471.62] loss=0.01 avg=0.01\n",
            "[877 | 472.06] loss=0.02 avg=0.01\n",
            "[878 | 472.51] loss=0.01 avg=0.01\n",
            "[879 | 472.96] loss=0.01 avg=0.01\n",
            "[880 | 473.41] loss=0.01 avg=0.01\n",
            "[881 | 473.85] loss=0.00 avg=0.01\n",
            "[882 | 474.30] loss=0.01 avg=0.01\n",
            "[883 | 474.75] loss=0.02 avg=0.01\n",
            "[884 | 475.19] loss=0.01 avg=0.01\n",
            "[885 | 475.64] loss=0.01 avg=0.01\n",
            "[886 | 476.08] loss=0.01 avg=0.01\n",
            "[887 | 476.53] loss=0.02 avg=0.01\n",
            "[888 | 476.97] loss=0.01 avg=0.01\n",
            "[889 | 477.42] loss=0.01 avg=0.01\n",
            "[890 | 477.87] loss=0.01 avg=0.01\n",
            "[891 | 478.31] loss=0.01 avg=0.01\n",
            "[892 | 478.76] loss=0.01 avg=0.01\n",
            "[893 | 479.21] loss=0.01 avg=0.01\n",
            "[894 | 479.65] loss=0.02 avg=0.01\n",
            "[895 | 480.10] loss=0.01 avg=0.01\n",
            "[896 | 480.54] loss=0.01 avg=0.01\n",
            "[897 | 480.99] loss=0.02 avg=0.01\n",
            "[898 | 481.44] loss=0.01 avg=0.01\n",
            "[899 | 481.88] loss=0.00 avg=0.01\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            "\n",
            "\n",
            "The inside of the home seemed to be more than a little risqué, with many empty seats, including the balcony and lower level seating. The stage leftful was well choreographed, with the stage almost entirely choreographing the moment during the second act when Aang arrived in the first act to announce his engagement to Saffrontean's house. As for the layout of the stage, there was a couch and a table in center stage for the first two acts, a door to the unseen outside front of the house upstage right, there were two large double doors upstage center leading to the backyard garden, and a raised floor upstage left containing a piano, a bookcase and a door leading to the home library. Stage left there was a half spiral staircase that lead up to the second floor which had a painting and lights that extended across to stage right. The second floor also contained the bedrooms for the house but the doors were not in sight. The detail was greater than expected: the hardwood floor throughout the first floor seemed to be genuine, the actual bookcase filled with real books not stage books, and the extremely large double doors with translucent glass and floral designs lead to the Garden, which featured an array of plants behind the doors. The entire space was well lit for the duration of the play; the stage took place inside the Bliss’ home so the bright lighting added a confortable feel to the inside of the house. The theatre was nearly sold out; it was hard to spot an empty seat, including the balcony, which was not even an empty seat in the first act. The crowd contained nearly an even amount of student audience members and senior citizens; there was few in the audience that appeared middle aged.\n",
            "\n",
            "The play was well cast, the entire Bliss family did a great job showing how overly dramatic and deceitful the family had become. Each actor portrayed their character accurately; there were no standouts that didn’t match the character. Each visitor in the first act seemed to be feasible as far as the possibility of a relationship was concerned. All of the family members acted genuine. There was one actor who stood out as a perfect fit for his character. Taylor Rascher played Simon Bliss and played him perfectly. Rascher’s character Simon was a young man who was dramatic and romantic so much so it was almost to the point of ridiculousness. Rascher stole the show in the first act when he was romancing with Michelle Luz, who plays Myra Arundel. Rascher was displaying his love for Michelle Luz (Myra) in the most dramatic of fashions; he was playing the Bliss’ game of pretending to be in complete love with someone and then a moment later change his mind. Rascher was proclaiming his love with elegant speeches and coddling up next to her and eventually kissing her. Rascher made this scene particularly hilarious because he was completely over the top in typical Bliss fashion. Of course, all of this was for naught because Luz ended up kissing Joe Hubbard’s character David Bliss in act two and also Rascher proclaimed his engagement to Caitlin Stagemoller’s character, Jackie Coryton. Rascher made his voice more shrill and audible to appear to be more dramatic and create more attention for himself. In the same way, Rascher used grander gestures with his arms (flailing, waving, etc.) to cause a more dramatic effect.\n",
            "\n",
            "The play was well interpreted by all whom were involved. Steven Wrentmore, the Director, kept the 1920’s feel by dressing in all 1920’s costumes and everyone spoke as if they were living at the time. Michelle Bisbee, the scene designer, made the inside of the home appear 1920’s because everything was grand. The Bliss’ home was grand with the spiral staircase, the very large backdoors, and the eloquent piano. The actors’ mannerisms seemed like they were portraying a silent film. In older movies, actors seemed very dramatic and had flamboyant actions to prove so; the actors in Hay Fever shared the same feel for the dramatics. As far as Stephen Wrentmore’s directing goes, he did an excellent job. The scene when Chris Karl (Richard) and Caitlin Stegemoller (Jackie) enter and are left alone to make small talk with each other is the best pertaining to directing. The two actors used the entire stage in this scene and were very awkward with one another. This was Wrentmore’s doing because you could tell he had a vision for this scene in particular because it seemed very crisp and well rehearsed. The actors played it perfect with the excessively long pauses in their awkward small talk that the crowd was laughing through the entire scene. It appeared that Wrentmore instructed the actors, to keep their pauses longer than natural to heighten the awkward tension in the scene, which made it brilliant.\n",
            "\n",
            "The blocking throughout the play worked\n",
            "\n",
            "[900 | 492.44] loss=0.01 avg=0.01\n",
            "[901 | 492.89] loss=0.01 avg=0.01\n",
            "[902 | 493.34] loss=0.01 avg=0.01\n",
            "[903 | 493.79] loss=0.01 avg=0.01\n",
            "[904 | 494.23] loss=0.00 avg=0.01\n",
            "[905 | 494.68] loss=0.01 avg=0.01\n",
            "[906 | 495.12] loss=0.02 avg=0.01\n",
            "[907 | 495.57] loss=0.01 avg=0.01\n",
            "[908 | 496.01] loss=0.01 avg=0.01\n",
            "[909 | 496.46] loss=0.01 avg=0.01\n",
            "[910 | 496.91] loss=0.01 avg=0.01\n",
            "[911 | 497.35] loss=0.01 avg=0.01\n",
            "[912 | 497.80] loss=0.00 avg=0.01\n",
            "[913 | 498.24] loss=0.00 avg=0.01\n",
            "[914 | 498.69] loss=0.01 avg=0.01\n",
            "[915 | 499.14] loss=0.00 avg=0.01\n",
            "[916 | 499.58] loss=0.01 avg=0.01\n",
            "[917 | 500.03] loss=0.01 avg=0.01\n",
            "[918 | 500.48] loss=0.01 avg=0.01\n",
            "[919 | 500.92] loss=0.01 avg=0.01\n",
            "[920 | 501.37] loss=0.01 avg=0.01\n",
            "[921 | 501.82] loss=0.01 avg=0.01\n",
            "[922 | 502.26] loss=0.00 avg=0.01\n",
            "[923 | 502.71] loss=0.01 avg=0.01\n",
            "[924 | 503.15] loss=0.01 avg=0.01\n",
            "[925 | 503.60] loss=0.01 avg=0.01\n",
            "[926 | 504.04] loss=0.01 avg=0.01\n",
            "[927 | 504.49] loss=0.01 avg=0.01\n",
            "[928 | 504.94] loss=0.01 avg=0.01\n",
            "[929 | 505.38] loss=0.01 avg=0.01\n",
            "[930 | 505.83] loss=0.01 avg=0.01\n",
            "[931 | 506.27] loss=0.00 avg=0.01\n",
            "[932 | 506.72] loss=0.01 avg=0.01\n",
            "[933 | 507.17] loss=0.01 avg=0.01\n",
            "[934 | 507.61] loss=0.01 avg=0.01\n",
            "[935 | 508.06] loss=0.03 avg=0.01\n",
            "[936 | 508.51] loss=0.01 avg=0.01\n",
            "[937 | 508.95] loss=0.00 avg=0.01\n",
            "[938 | 509.40] loss=0.01 avg=0.01\n",
            "[939 | 509.85] loss=0.02 avg=0.01\n",
            "[940 | 510.29] loss=0.01 avg=0.01\n",
            "[941 | 510.74] loss=0.02 avg=0.01\n",
            "[942 | 511.18] loss=0.00 avg=0.01\n",
            "[943 | 511.63] loss=0.01 avg=0.01\n",
            "[944 | 512.08] loss=0.01 avg=0.01\n",
            "[945 | 512.52] loss=0.01 avg=0.01\n",
            "[946 | 512.97] loss=0.01 avg=0.01\n",
            "[947 | 513.41] loss=0.01 avg=0.01\n",
            "[948 | 513.86] loss=0.01 avg=0.01\n",
            "[949 | 514.31] loss=0.01 avg=0.01\n",
            "[950 | 514.75] loss=0.02 avg=0.01\n",
            "[951 | 515.20] loss=0.01 avg=0.01\n",
            "[952 | 515.65] loss=0.01 avg=0.01\n",
            "[953 | 516.09] loss=0.01 avg=0.01\n",
            "[954 | 516.54] loss=0.01 avg=0.01\n",
            "[955 | 516.98] loss=0.01 avg=0.01\n",
            "[956 | 517.43] loss=0.01 avg=0.01\n",
            "[957 | 517.88] loss=0.01 avg=0.01\n",
            "[958 | 518.32] loss=0.00 avg=0.01\n",
            "[959 | 518.77] loss=0.01 avg=0.01\n",
            "[960 | 519.21] loss=0.01 avg=0.01\n",
            "[961 | 519.66] loss=0.01 avg=0.01\n",
            "[962 | 520.11] loss=0.01 avg=0.01\n",
            "[963 | 520.56] loss=0.01 avg=0.01\n",
            "[964 | 521.00] loss=0.02 avg=0.01\n",
            "[965 | 521.45] loss=0.01 avg=0.01\n",
            "[966 | 521.89] loss=0.01 avg=0.01\n",
            "[967 | 522.34] loss=0.01 avg=0.01\n",
            "[968 | 522.79] loss=0.01 avg=0.01\n",
            "[969 | 523.23] loss=0.02 avg=0.01\n",
            "[970 | 523.68] loss=0.01 avg=0.01\n",
            "[971 | 524.13] loss=0.01 avg=0.01\n",
            "[972 | 524.57] loss=0.01 avg=0.01\n",
            "[973 | 525.02] loss=0.01 avg=0.01\n",
            "[974 | 525.47] loss=0.01 avg=0.01\n",
            "[975 | 525.92] loss=0.01 avg=0.01\n",
            "[976 | 526.36] loss=0.02 avg=0.01\n",
            "[977 | 526.81] loss=0.01 avg=0.01\n",
            "[978 | 527.26] loss=0.01 avg=0.01\n",
            "[979 | 527.70] loss=0.01 avg=0.01\n",
            "[980 | 528.15] loss=0.01 avg=0.01\n",
            "[981 | 528.60] loss=0.01 avg=0.01\n",
            "[982 | 529.05] loss=0.01 avg=0.01\n",
            "[983 | 529.49] loss=0.01 avg=0.01\n",
            "[984 | 529.94] loss=0.01 avg=0.01\n",
            "[985 | 530.39] loss=0.02 avg=0.01\n",
            "[986 | 530.83] loss=0.01 avg=0.01\n",
            "[987 | 531.28] loss=0.01 avg=0.01\n",
            "[988 | 531.73] loss=0.01 avg=0.01\n",
            "[989 | 532.17] loss=0.01 avg=0.01\n",
            "[990 | 532.62] loss=0.01 avg=0.01\n",
            "[991 | 533.07] loss=0.00 avg=0.01\n",
            "[992 | 533.51] loss=0.01 avg=0.01\n",
            "[993 | 533.96] loss=0.02 avg=0.01\n",
            "[994 | 534.41] loss=0.01 avg=0.01\n",
            "[995 | 534.86] loss=0.01 avg=0.01\n",
            "[996 | 535.30] loss=0.01 avg=0.01\n",
            "[997 | 535.75] loss=0.01 avg=0.01\n",
            "[998 | 536.20] loss=0.01 avg=0.01\n",
            "[999 | 536.64] loss=0.01 avg=0.01\n",
            "Saving checkpoint/run1/model-1000\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " through a raised floor upstage left containing a piano, a bookcase and a door leading to the home library. Stage left there was a half spiral staircase that lead up to the second floor which had a painting and lights that extended across to stage right. The second floor also contained the bedrooms for the house but the doors were not in sight. The detail was greater than expected: the hardwood floor overlined the space to the wall; the prepared floor seemed to be genuine, the seats seemed to be real, and the trees seemed to be in the distance such that it was likely a few hundred people were inside the house at one time. The entire space was well lit for the duration of the play; the stage took place inside the Bliss’ home so the bright lighting added a confortable feel to the inside of the house. The theatre was nearly sold out; it was hard to spot an empty seat, including the balcony and lower level seating. The crowd contained nearly an even amount of student audience members and senior citizens; there was few in the audience that appeared middle aged.\n",
            "\n",
            "The play was well cast, the entire Bliss family did a great job showing how overly dramatic and deceitful the family had become. Each actor portrayed their character accurately; there were no standouts that didn’t match the character. Each visitor in the first act seemed to be feasible as far as the possibility of a relationship was concerned. All of the family members acted genuine. There was one actor who stood out as a perfect fit for his character. Taylor Rascher played Simon Bliss and played him perfectly. Rascher’s character Simon was a young man who was dramatic and romantic so much so it was almost to the point of ridiculousness. Rascher stole the show in the first act when he was romancing with Michelle Luz, who plays Myra Arundel. Rascher was displaying his love for Michelle Luz (Myra) in the most dramatic of fashions; he was playing the Bliss’ game of pretending to be in complete love with someone and then a moment later change his mind. Rascher was proclaiming his love with elegant speeches and coddling up next to her and eventually kissing her. Rascher made this scene particularly hilarious because he was completely over the top in typical Bliss fashion. Of course, all of this was for naught because Luz ended up kissing Joe Hubbard’s character David Bliss in act two and also Rascher proclaimed his engagement to Caitlin Stagemoller’s character, Jackie Coryton. Rascher made his voice more shrill and audible to appear to be more dramatic and create more attention for himself. In the same way, Rascher used grander gestures with his arms (flailing, waving, etc.) to cause a more dramatic effect.\n",
            "\n",
            "The play was well interpreted by all whom were involved. Steven Wrentmore, the Director, kept the 1920’s feel by dressing in all 1920’s costumes and everyone spoke as if they were living at the time. Michelle Bisbee, the scene designer, made the inside of the home appear 1920’s because everything was grand. The Bliss’ home was grand with the spiral staircase, the very large backdoors, and the eloquent piano. The actors’ mannerisms seemed like they were portraying a silent film. In older movies, actors seemed very dramatic and had flamboyant actions to prove so; the actors in Hay Fever shared the same feel for the dramatics. As far as Stephen Wrentmore’s directing goes, he did an excellent job. The scene when Chris Karl (Richard) and Caitlin Stegemoller (Jackie) enter and are left alone to make small talk with each other is the best pertaining to directing. The two actors used the entire stage in this scene and were very awkward with one another. This was Wrentmore’s doing because you could tell he had a vision for this scene in particular because it seemed very crisp and well rehearsed. The actors played it perfect with the excessively long pauses in their awkward small talk that the crowd was laughing through the entire scene. It appeared that Wrentmore instructed the actors, to keep their pauses longer than natural to heighten the awkward tension in the scene, which made it brilliant.\n",
            "\n",
            "The blocking throughout the play worked with the floor plan very well. All of the blocking worked seamlessly; the actors were never out of sight or in awkward positioning (ex. turned around, talking to someone behind them while face forward, etc.) even during the second act in the first scene while all eight actors were on set. One part of the set that stood out was the staircase, it is obviously very large, but the way Owen Virgin followed Megan Davis up the stairs was seamless. They both walked up the stairs with footsteps I unison, and Owen Virgin was so focused on every detail of Davis, it almost screamed out how much he was infatuated with her.\n",
            "\n",
            "The artistic intent of this\n",
            "\n",
            "[1000 | 550.83] loss=0.01 avg=0.01\n",
            "[1001 | 551.29] loss=0.01 avg=0.01\n",
            "[1002 | 551.73] loss=0.01 avg=0.01\n",
            "[1003 | 552.18] loss=0.01 avg=0.01\n",
            "[1004 | 552.63] loss=0.00 avg=0.01\n",
            "[1005 | 553.07] loss=0.01 avg=0.01\n",
            "[1006 | 553.52] loss=0.01 avg=0.01\n",
            "[1007 | 553.97] loss=0.01 avg=0.01\n",
            "[1008 | 554.41] loss=0.01 avg=0.01\n",
            "[1009 | 554.86] loss=0.01 avg=0.01\n",
            "[1010 | 555.31] loss=0.01 avg=0.01\n",
            "[1011 | 555.75] loss=0.01 avg=0.01\n",
            "[1012 | 556.20] loss=0.00 avg=0.01\n",
            "[1013 | 556.65] loss=0.01 avg=0.01\n",
            "[1014 | 557.09] loss=0.01 avg=0.01\n",
            "[1015 | 557.54] loss=0.02 avg=0.01\n",
            "[1016 | 557.98] loss=0.01 avg=0.01\n",
            "[1017 | 558.43] loss=0.00 avg=0.01\n",
            "[1018 | 558.88] loss=0.01 avg=0.01\n",
            "[1019 | 559.32] loss=0.01 avg=0.01\n",
            "[1020 | 559.77] loss=0.01 avg=0.01\n",
            "[1021 | 560.21] loss=0.00 avg=0.01\n",
            "[1022 | 560.66] loss=0.01 avg=0.01\n",
            "[1023 | 561.11] loss=0.00 avg=0.01\n",
            "[1024 | 561.56] loss=0.01 avg=0.01\n",
            "[1025 | 562.00] loss=0.01 avg=0.01\n",
            "[1026 | 562.45] loss=0.01 avg=0.01\n",
            "[1027 | 562.90] loss=0.01 avg=0.01\n",
            "[1028 | 563.34] loss=0.02 avg=0.01\n",
            "[1029 | 563.79] loss=0.00 avg=0.01\n",
            "[1030 | 564.24] loss=0.01 avg=0.01\n",
            "[1031 | 564.68] loss=0.01 avg=0.01\n",
            "[1032 | 565.13] loss=0.01 avg=0.01\n",
            "[1033 | 565.58] loss=0.01 avg=0.01\n",
            "[1034 | 566.02] loss=0.01 avg=0.01\n",
            "[1035 | 566.47] loss=0.01 avg=0.01\n",
            "[1036 | 566.92] loss=0.00 avg=0.01\n",
            "[1037 | 567.36] loss=0.01 avg=0.01\n",
            "[1038 | 567.81] loss=0.01 avg=0.01\n",
            "[1039 | 568.25] loss=0.00 avg=0.01\n",
            "[1040 | 568.70] loss=0.01 avg=0.01\n",
            "[1041 | 569.15] loss=0.01 avg=0.01\n",
            "[1042 | 569.60] loss=0.01 avg=0.01\n",
            "[1043 | 570.04] loss=0.01 avg=0.01\n",
            "[1044 | 570.49] loss=0.01 avg=0.01\n",
            "[1045 | 570.93] loss=0.01 avg=0.01\n",
            "[1046 | 571.38] loss=0.01 avg=0.01\n",
            "[1047 | 571.83] loss=0.01 avg=0.01\n",
            "interrupted\n",
            "Saving checkpoint/run1/model-1048\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWyIgvYFoPHd"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2/checkpoint/run1/* /content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2/models/124M/"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il0FVF7kZC4q",
        "outputId": "858d44f8-532f-49b1-f14e-cc2ee2e82131",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2/src/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wonSh4yhnOt-",
        "outputId": "9b951f0a-1024-43eb-99dd-3aae2c366a76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python src/interactive_conditional_samples.py — top_k 40\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 91, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 47, in interact_model\n",
            "    enc = encoder.get_encoder(model_name, models_dir)\n",
            "  File \"/content/drive/My Drive/gpt2finetune/gpt-2/gpt-2/src/encoder.py\", line 116, in get_encoder\n",
            "    bpe_merges=bpe_merges,\n",
            "  File \"/content/drive/My Drive/gpt2finetune/gpt-2/gpt-2/src/encoder.py\", line 47, in __init__\n",
            "    self.byte_encoder = bytes_to_unicode()\n",
            "  File \"/content/drive/My Drive/gpt2finetune/gpt-2/gpt-2/src/encoder.py\", line 19, in bytes_to_unicode\n",
            "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"Â¡\"), ord(\"Â¬\")+1))+list(range(ord(\"Â®\"), ord(\"Ã¿\")+1))\n",
            "TypeError: ord() expected a character, but string of length 2 found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdOpenqWoYZA",
        "outputId": "1fbf1a9c-e67f-42d8-d50c-0821c29c822a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "%cd /content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/gpt2finetune/gpt-2/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDpUckZ7TLfJ",
        "outputId": "fdd7c017-b0a4-44e9-d4d9-d77bb38fcccb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t Dockerfile.gpu     LICENSE\t   requirements.txt  twremat\n",
            "CONTRIBUTORS.md  domains.txt\t    model_card.md  samples\n",
            "DEVELOPERS.md\t download_model.py  models\t   src\n",
            "Dockerfile.cpu\t encode.py\t    README.md\t   train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSiztPiaTVnG",
        "outputId": "9b365a55-40f5-4998-a27e-5138efbe4229",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd models/124M/\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/gpt2finetune/gpt-2/gpt-2/models/124M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq2iN0mCeoJz",
        "outputId": "a5edb42f-0c8f-43c6-9fb3-adda2c807c84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t\t     model-1000.meta\n",
            "counter\t\t\t\t\t     model-1048.data-00000-of-00001\n",
            "encoder.json\t\t\t\t     model-1048.index\n",
            "events.out.tfevents.1627664019.2b40aee92a47  model.ckpt.data-00000-of-00001\n",
            "hparams.json\t\t\t\t     model.ckpt.index\n",
            "model-1000.data-00000-of-00001\t\t     model.ckpt.meta\n",
            "model-1000.index\t\t\t     vocab.bpe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8IibrpPeq74"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}